{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "436e1e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "pdir = os.path.dirname(os.getcwd())\n",
    "sys.path.append(pdir)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import wandb\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import utils\n",
    "from simpleview_pytorch import SimpleView\n",
    "\n",
    "from torch.utils.data.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8bf28aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmja2106\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c008cf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90c30d3",
   "metadata": {},
   "source": [
    "### Load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af85ef95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEFAG     1116\n",
      "PINNIG      581\n",
      "QUEILE      364\n",
      "PINSYL      277\n",
      "PINPIN      140\n",
      "JUNIPE        2\n",
      "QUERCUS       2\n",
      "NA            2\n",
      "DEAD          1\n",
      "Name: sp, dtype: int64\n",
      "Species:  ['DEAD', 'JUNIPE', 'NA', 'PINNIG', 'PINPIN', 'PINSYL', 'QUEFAG', 'QUEILE', 'QUERCUS']\n",
      "Labels:  tensor([8, 3, 6,  ..., 7, 3, 6])\n",
      "Total count:  2485\n"
     ]
    }
   ],
   "source": [
    "trees_data = torch.load('trees_256.pt')\n",
    "print(trees_data.counts)\n",
    "print('Species: ', trees_data.species)\n",
    "print('Labels: ', trees_data.labels)\n",
    "print('Total count: ', len(trees_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac987139",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.30 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.15<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">worthy-frost-61</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mja2106/laser-trees\" target=\"_blank\">https://wandb.ai/mja2106/laser-trees</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/mja2106/laser-trees/runs/26jklf2p\" target=\"_blank\">https://wandb.ai/mja2106/laser-trees/runs/26jklf2p</a><br/>\n",
       "                Run data is saved locally in <code>/home/matt/Work/MRes-Project/laser-trees/notebooks/wandb/run-20210508_170039-26jklf2p</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f189bb5ff10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    \"dataset_type\":type(trees_data),\n",
    "    \"batch_size\":128,\n",
    "    \"validation_split\":.2,\n",
    "    \"shuffle_dataset\":True,\n",
    "    \"random_seed\":0,\n",
    "    \"learning_rate\":0.0005,\n",
    "    \"momentum\":0.9,\n",
    "    \"epochs\":100,\n",
    "    \"loss_fn\":\"smooth-loss\",\n",
    "    \"optimizer\":\"adam\",\n",
    "    \"jitter\":False,\n",
    "    \"random_rotation\":False,\n",
    "    \"random_scaling\":False,\n",
    "    \"random_translation\":False,\n",
    "    \"voting\":\"None\",\n",
    "    \n",
    "    \"model\":\"SimpleView\",\n",
    "    \n",
    "    \"image_dim\":trees_data.image_dim,\n",
    "    \"camera_fov_deg\":trees_data.camera_fov_deg,\n",
    "    \"f\":trees_data.f,\n",
    "    \"camera_dist\":trees_data.camera_dist,\n",
    "    \"depth_averaging\":\"min\",\n",
    "    \n",
    "    \"species\":[\"QUEFAG\", \"PINNIG\", \"QUEILE\", \"PINSYL\", \"PINPIN\"],\n",
    "    \"data_resolution\":\"2.5cm\"\n",
    "}\n",
    "\n",
    "\n",
    "if params[\"dataset_type\"] == utils.dataset.TreeSpeciesPointDataset: #Change these by hand using point dataset\n",
    "    params[\"image_dim\"] = 256\n",
    "    params[\"camera_fov_deg\"] = 90 \n",
    "    params[\"f\"] = 1\n",
    "    params[\"camera_dist\"] = 1.4\n",
    "    params[\"depth_averaging\"] = \"min\"\n",
    "    params[\"soft_min_k\"] = 50\n",
    "    params[\"num_views\"] = 6\n",
    "    \n",
    "    trees_data.set_params(image_dim = params[\"image_dim\"],\n",
    "                         camera_fov_deg = params[\"camera_fov_deg\"],\n",
    "                         f = params[\"f\"],\n",
    "                         camera_dist = params[\"camera_dist\"],\n",
    "                         soft_min_k = params[\"soft_min_k\"])  \n",
    "    \n",
    "elif params[\"dataset_type\"] == utils.dataset.TreeSpeciesDataset:\n",
    "    params[\"image_dim\"] = trees_data.image_dim\n",
    "    params[\"camera_fov_deg\"] = trees_data.camera_fov_deg\n",
    "    params[\"f\"] = trees_data.f\n",
    "    params[\"camera_dist\"] = trees_data.camera_dist\n",
    "    params[\"num_views\"] = trees_data.depth_images.shape[1]\n",
    "    params[\"depth_averaging\"] = \"min\"\n",
    "\n",
    "    \n",
    "if trees_data.soft_min_k:\n",
    "    params[\"soft_min_k\"] = trees_data.soft_min_k\n",
    "\n",
    "experiment_name = wandb.util.generate_id()\n",
    "    \n",
    "run = wandb.init(\n",
    "    project='laser-trees',\n",
    "    group=experiment_name,\n",
    "    config=params)    \n",
    "\n",
    "config = wandb.config\n",
    "torch.manual_seed(config.random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8328306",
   "metadata": {},
   "source": [
    "#### Remove low-count species:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8115a508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing: QUERCUS\n",
      "Removing: JUNIPE\n",
      "Removing: NA\n",
      "Removing: DEAD\n",
      "QUEFAG    1116\n",
      "PINNIG     581\n",
      "QUEILE     364\n",
      "PINSYL     277\n",
      "PINPIN     140\n",
      "Name: sp, dtype: int64\n",
      "Species:  ['PINNIG', 'PINPIN', 'PINSYL', 'QUEFAG', 'QUEILE']\n",
      "Labels:  tensor([0, 3, 3,  ..., 4, 0, 3])\n",
      "Total count:  2478\n"
     ]
    }
   ],
   "source": [
    "for specie in list(set(trees_data.species) - set(config.species)):\n",
    "    print(\"Removing: {}\".format(specie))\n",
    "    trees_data.remove_species(specie)\n",
    "    \n",
    "print(trees_data.counts)\n",
    "print('Species: ', trees_data.species)\n",
    "print('Labels: ', trees_data.labels)\n",
    "print('Total count: ', len(trees_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9aa0865",
   "metadata": {},
   "source": [
    "#### Train-validation split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed7d3c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(trees_data)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(config.validation_split * dataset_size))\n",
    "\n",
    "if config.shuffle_dataset :\n",
    "    np.random.seed(config.random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95aaedb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trees_data, batch_size=config.batch_size, \n",
    "                                           sampler=train_sampler)\n",
    "validation_loader = torch.utils.data.DataLoader(trees_data, batch_size=config.batch_size,\n",
    "                                                sampler=valid_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b131551d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run to print no. instances of each class\n",
    "if None:\n",
    "    for x in train_loader:\n",
    "        print(torch.unique(x['labels'], return_counts = True))\n",
    "    print()\n",
    "\n",
    "    for x in validation_loader:\n",
    "        print(torch.unique(x['labels'], return_counts = True))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb521b79",
   "metadata": {},
   "source": [
    "### Define model, loss fn, optimiser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d0ebfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(config.species) == set(trees_data.species)\n",
    "\n",
    "if config.model==\"SimpleView\":\n",
    "    model = SimpleView(\n",
    "        num_views=config.num_views,\n",
    "        num_classes=len(config.species)\n",
    "    )\n",
    "\n",
    "model = model.to(device=device)\n",
    "\n",
    "if config.loss_fn==\"cross-entropy\":\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "if config.loss_fn==\"smooth-loss\":\n",
    "    loss_fn = utils.smooth_loss\n",
    "\n",
    "if config.optimizer==\"sgd\":\n",
    "    optimizer = optim.SGD(model.parameters(), lr=config.learning_rate, momentum=config.momentum)\n",
    "elif config.optimizer==\"adam\":\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a765145",
   "metadata": {},
   "source": [
    "### Train & Test Loops:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "478779ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     5] loss: 3.661\n",
      "[1,    10] loss: 3.485\n",
      "[1,    15] loss: 3.387\n",
      "Got 46 / 495 with accuracy 9.29\n",
      "[2,     5] loss: 3.261\n",
      "[2,    10] loss: 3.134\n",
      "[2,    15] loss: 3.134\n",
      "Got 130 / 495 with accuracy 26.26\n",
      "[3,     5] loss: 3.030\n",
      "[3,    10] loss: 3.075\n",
      "[3,    15] loss: 3.006\n",
      "Got 305 / 495 with accuracy 61.62\n",
      "[4,     5] loss: 2.931\n",
      "[4,    10] loss: 2.930\n",
      "[4,    15] loss: 2.886\n",
      "Got 339 / 495 with accuracy 68.48\n",
      "[5,     5] loss: 2.792\n",
      "[5,    10] loss: 2.780\n",
      "[5,    15] loss: 2.769\n",
      "Got 298 / 495 with accuracy 60.20\n",
      "[6,     5] loss: 2.640\n",
      "[6,    10] loss: 2.545\n",
      "[6,    15] loss: 2.596\n",
      "Got 204 / 495 with accuracy 41.21\n",
      "[7,     5] loss: 2.433\n",
      "[7,    10] loss: 2.417\n",
      "[7,    15] loss: 2.396\n",
      "Got 295 / 495 with accuracy 59.60\n",
      "[8,     5] loss: 2.269\n",
      "[8,    10] loss: 2.201\n",
      "[8,    15] loss: 2.229\n",
      "Got 286 / 495 with accuracy 57.78\n",
      "[9,     5] loss: 2.121\n",
      "[9,    10] loss: 2.123\n",
      "[9,    15] loss: 2.110\n",
      "Got 298 / 495 with accuracy 60.20\n",
      "[10,     5] loss: 2.046\n",
      "[10,    10] loss: 2.048\n",
      "[10,    15] loss: 2.044\n",
      "Got 271 / 495 with accuracy 54.75\n",
      "[11,     5] loss: 2.012\n",
      "[11,    10] loss: 2.005\n",
      "[11,    15] loss: 2.003\n",
      "Got 318 / 495 with accuracy 64.24\n",
      "[12,     5] loss: 1.989\n",
      "[12,    10] loss: 1.983\n",
      "[12,    15] loss: 1.987\n",
      "Got 307 / 495 with accuracy 62.02\n",
      "[13,     5] loss: 1.980\n",
      "[13,    10] loss: 1.978\n",
      "[13,    15] loss: 1.976\n",
      "Got 309 / 495 with accuracy 62.42\n",
      "[14,     5] loss: 1.969\n",
      "[14,    10] loss: 1.972\n",
      "[14,    15] loss: 1.970\n",
      "Got 318 / 495 with accuracy 64.24\n",
      "[15,     5] loss: 1.967\n",
      "[15,    10] loss: 1.972\n",
      "[15,    15] loss: 1.970\n",
      "Got 292 / 495 with accuracy 58.99\n",
      "[16,     5] loss: 1.965\n",
      "[16,    10] loss: 1.981\n",
      "[16,    15] loss: 1.979\n",
      "Got 280 / 495 with accuracy 56.57\n",
      "[17,     5] loss: 1.974\n",
      "[17,    10] loss: 1.973\n",
      "[17,    15] loss: 1.970\n",
      "Got 290 / 495 with accuracy 58.59\n",
      "[18,     5] loss: 1.969\n",
      "[18,    10] loss: 1.969\n",
      "[18,    15] loss: 1.968\n",
      "Got 306 / 495 with accuracy 61.82\n",
      "[19,     5] loss: 1.963\n",
      "[19,    10] loss: 1.963\n",
      "[19,    15] loss: 1.962\n",
      "Got 292 / 495 with accuracy 58.99\n",
      "[20,     5] loss: 1.964\n",
      "[20,    10] loss: 1.964\n",
      "[20,    15] loss: 1.964\n",
      "Got 273 / 495 with accuracy 55.15\n",
      "[21,     5] loss: 1.961\n",
      "[21,    10] loss: 1.959\n",
      "[21,    15] loss: 1.960\n",
      "Got 307 / 495 with accuracy 62.02\n",
      "[22,     5] loss: 1.958\n",
      "[22,    10] loss: 1.967\n",
      "[22,    15] loss: 1.964\n",
      "Got 312 / 495 with accuracy 63.03\n",
      "[23,     5] loss: 1.961\n",
      "[23,    10] loss: 1.961\n",
      "[23,    15] loss: 1.968\n",
      "Got 322 / 495 with accuracy 65.05\n",
      "[24,     5] loss: 1.964\n",
      "[24,    10] loss: 1.959\n",
      "[24,    15] loss: 1.962\n",
      "Got 312 / 495 with accuracy 63.03\n",
      "[25,     5] loss: 1.960\n",
      "[25,    10] loss: 1.964\n",
      "[25,    15] loss: 1.964\n",
      "Got 316 / 495 with accuracy 63.84\n",
      "[26,     5] loss: 1.957\n",
      "[26,    10] loss: 1.962\n",
      "[26,    15] loss: 1.960\n",
      "Got 326 / 495 with accuracy 65.86\n",
      "[27,     5] loss: 1.956\n",
      "[27,    10] loss: 1.957\n",
      "[27,    15] loss: 1.955\n",
      "Got 302 / 495 with accuracy 61.01\n",
      "[28,     5] loss: 1.956\n",
      "[28,    10] loss: 1.958\n",
      "[28,    15] loss: 1.957\n",
      "Got 330 / 495 with accuracy 66.67\n",
      "[29,     5] loss: 1.958\n",
      "[29,    10] loss: 1.959\n",
      "[29,    15] loss: 1.958\n",
      "Got 306 / 495 with accuracy 61.82\n",
      "[30,     5] loss: 1.958\n",
      "[30,    10] loss: 1.955\n",
      "[30,    15] loss: 1.959\n",
      "Got 324 / 495 with accuracy 65.45\n",
      "[31,     5] loss: 1.960\n",
      "[31,    10] loss: 1.957\n",
      "[31,    15] loss: 1.959\n",
      "Got 309 / 495 with accuracy 62.42\n",
      "[32,     5] loss: 1.954\n",
      "[32,    10] loss: 1.960\n",
      "[32,    15] loss: 1.960\n",
      "Got 323 / 495 with accuracy 65.25\n",
      "[33,     5] loss: 1.965\n",
      "[33,    10] loss: 1.959\n",
      "[33,    15] loss: 1.961\n",
      "Got 319 / 495 with accuracy 64.44\n",
      "[34,     5] loss: 1.958\n",
      "[34,    10] loss: 1.961\n",
      "[34,    15] loss: 1.959\n",
      "Got 316 / 495 with accuracy 63.84\n",
      "[35,     5] loss: 1.961\n",
      "[35,    10] loss: 1.964\n",
      "[35,    15] loss: 1.959\n",
      "Got 293 / 495 with accuracy 59.19\n",
      "[36,     5] loss: 1.957\n",
      "[36,    10] loss: 1.956\n",
      "[36,    15] loss: 1.956\n",
      "Got 329 / 495 with accuracy 66.46\n",
      "[37,     5] loss: 1.952\n",
      "[37,    10] loss: 1.957\n",
      "[37,    15] loss: 1.959\n",
      "Got 315 / 495 with accuracy 63.64\n",
      "[38,     5] loss: 1.955\n",
      "[38,    10] loss: 1.955\n",
      "[38,    15] loss: 1.957\n",
      "Got 323 / 495 with accuracy 65.25\n",
      "[39,     5] loss: 1.959\n",
      "[39,    10] loss: 1.961\n",
      "[39,    15] loss: 1.956\n",
      "Got 311 / 495 with accuracy 62.83\n",
      "[40,     5] loss: 1.956\n",
      "[40,    10] loss: 1.956\n",
      "[40,    15] loss: 1.957\n",
      "Got 327 / 495 with accuracy 66.06\n",
      "[41,     5] loss: 1.959\n",
      "[41,    10] loss: 1.961\n",
      "[41,    15] loss: 1.958\n",
      "Got 302 / 495 with accuracy 61.01\n",
      "[42,     5] loss: 1.960\n",
      "[42,    10] loss: 1.960\n",
      "[42,    15] loss: 1.958\n",
      "Got 331 / 495 with accuracy 66.87\n",
      "[43,     5] loss: 1.956\n",
      "[43,    10] loss: 1.957\n",
      "[43,    15] loss: 1.961\n",
      "Got 310 / 495 with accuracy 62.63\n",
      "[44,     5] loss: 1.959\n",
      "[44,    10] loss: 1.956\n",
      "[44,    15] loss: 1.959\n",
      "Got 322 / 495 with accuracy 65.05\n",
      "[45,     5] loss: 1.960\n",
      "[45,    10] loss: 1.960\n",
      "[45,    15] loss: 1.960\n",
      "Got 287 / 495 with accuracy 57.98\n",
      "[46,     5] loss: 1.957\n",
      "[46,    10] loss: 1.969\n",
      "[46,    15] loss: 1.967\n",
      "Got 296 / 495 with accuracy 59.80\n",
      "[47,     5] loss: 1.968\n",
      "[47,    10] loss: 1.959\n",
      "[47,    15] loss: 1.964\n",
      "Got 317 / 495 with accuracy 64.04\n",
      "[48,     5] loss: 1.958\n",
      "[48,    10] loss: 1.960\n",
      "[48,    15] loss: 1.958\n",
      "Got 325 / 495 with accuracy 65.66\n",
      "[49,     5] loss: 1.956\n",
      "[49,    10] loss: 1.963\n",
      "[49,    15] loss: 1.958\n",
      "Got 307 / 495 with accuracy 62.02\n",
      "[50,     5] loss: 1.957\n",
      "[50,    10] loss: 1.956\n",
      "[50,    15] loss: 1.955\n",
      "Got 332 / 495 with accuracy 67.07\n",
      "[51,     5] loss: 1.953\n",
      "[51,    10] loss: 1.954\n",
      "[51,    15] loss: 1.952\n",
      "Got 325 / 495 with accuracy 65.66\n",
      "[52,     5] loss: 1.952\n",
      "[52,    10] loss: 1.951\n",
      "[52,    15] loss: 1.952\n",
      "Got 318 / 495 with accuracy 64.24\n",
      "[53,     5] loss: 1.951\n",
      "[53,    10] loss: 1.953\n",
      "[53,    15] loss: 1.952\n",
      "Got 325 / 495 with accuracy 65.66\n",
      "[54,     5] loss: 1.951\n",
      "[54,    10] loss: 1.954\n",
      "[54,    15] loss: 1.955\n",
      "Got 314 / 495 with accuracy 63.43\n",
      "[55,     5] loss: 1.953\n",
      "[55,    10] loss: 1.954\n",
      "[55,    15] loss: 1.954\n",
      "Got 302 / 495 with accuracy 61.01\n",
      "[56,     5] loss: 1.957\n",
      "[56,    10] loss: 1.956\n",
      "[56,    15] loss: 1.957\n",
      "Got 307 / 495 with accuracy 62.02\n",
      "[57,     5] loss: 1.954\n",
      "[57,    10] loss: 1.953\n",
      "[57,    15] loss: 1.956\n",
      "Got 334 / 495 with accuracy 67.47\n",
      "[58,     5] loss: 1.955\n",
      "[58,    10] loss: 1.960\n",
      "[58,    15] loss: 1.960\n",
      "Got 312 / 495 with accuracy 63.03\n",
      "[59,     5] loss: 1.958\n",
      "[59,    10] loss: 1.955\n",
      "[59,    15] loss: 1.954\n",
      "Got 304 / 495 with accuracy 61.41\n",
      "[60,     5] loss: 1.956\n",
      "[60,    10] loss: 1.956\n",
      "[60,    15] loss: 1.953\n",
      "Got 321 / 495 with accuracy 64.85\n",
      "[61,     5] loss: 1.955\n",
      "[61,    10] loss: 1.954\n",
      "[61,    15] loss: 1.952\n",
      "Got 322 / 495 with accuracy 65.05\n",
      "[62,     5] loss: 1.955\n",
      "[62,    10] loss: 1.953\n",
      "[62,    15] loss: 1.957\n",
      "Got 323 / 495 with accuracy 65.25\n",
      "[63,     5] loss: 1.957\n",
      "[63,    10] loss: 1.953\n",
      "[63,    15] loss: 1.954\n",
      "Got 320 / 495 with accuracy 64.65\n",
      "[64,     5] loss: 1.953\n",
      "[64,    10] loss: 1.952\n",
      "[64,    15] loss: 1.953\n",
      "Got 320 / 495 with accuracy 64.65\n",
      "[65,     5] loss: 1.952\n",
      "[65,    10] loss: 1.954\n",
      "[65,    15] loss: 1.958\n",
      "Got 324 / 495 with accuracy 65.45\n",
      "[66,     5] loss: 1.955\n",
      "[66,    10] loss: 1.961\n",
      "[66,    15] loss: 1.957\n",
      "Got 306 / 495 with accuracy 61.82\n",
      "[67,     5] loss: 1.955\n",
      "[67,    10] loss: 1.957\n",
      "[67,    15] loss: 1.957\n",
      "Got 319 / 495 with accuracy 64.44\n",
      "[68,     5] loss: 1.953\n",
      "[68,    10] loss: 1.954\n",
      "[68,    15] loss: 1.956\n",
      "Got 329 / 495 with accuracy 66.46\n",
      "[69,     5] loss: 1.952\n",
      "[69,    10] loss: 1.952\n",
      "[69,    15] loss: 1.952\n",
      "Got 326 / 495 with accuracy 65.86\n",
      "[70,     5] loss: 1.953\n",
      "[70,    10] loss: 1.953\n",
      "[70,    15] loss: 1.955\n",
      "Got 326 / 495 with accuracy 65.86\n",
      "[71,     5] loss: 1.953\n",
      "[71,    10] loss: 1.955\n",
      "[71,    15] loss: 1.952\n",
      "Got 330 / 495 with accuracy 66.67\n",
      "[72,     5] loss: 1.955\n",
      "[72,    10] loss: 1.954\n",
      "[72,    15] loss: 1.955\n",
      "Got 330 / 495 with accuracy 66.67\n",
      "[73,     5] loss: 1.955\n",
      "[73,    10] loss: 1.955\n",
      "[73,    15] loss: 1.954\n",
      "Got 321 / 495 with accuracy 64.85\n",
      "[74,     5] loss: 1.952\n",
      "[74,    10] loss: 1.952\n",
      "[74,    15] loss: 1.953\n",
      "Got 331 / 495 with accuracy 66.87\n",
      "[75,     5] loss: 1.952\n",
      "[75,    10] loss: 1.954\n",
      "[75,    15] loss: 1.956\n",
      "Got 325 / 495 with accuracy 65.66\n",
      "[76,     5] loss: 1.956\n",
      "[76,    10] loss: 1.956\n",
      "[76,    15] loss: 1.956\n",
      "Got 327 / 495 with accuracy 66.06\n",
      "[77,     5] loss: 1.954\n",
      "[77,    10] loss: 1.957\n",
      "[77,    15] loss: 1.956\n",
      "Got 332 / 495 with accuracy 67.07\n",
      "[78,     5] loss: 1.953\n",
      "[78,    10] loss: 1.953\n",
      "[78,    15] loss: 1.953\n",
      "Got 327 / 495 with accuracy 66.06\n",
      "[79,     5] loss: 1.953\n",
      "[79,    10] loss: 1.952\n",
      "[79,    15] loss: 1.953\n",
      "Got 330 / 495 with accuracy 66.67\n",
      "[80,     5] loss: 1.953\n",
      "[80,    10] loss: 1.954\n",
      "[80,    15] loss: 1.951\n",
      "Got 317 / 495 with accuracy 64.04\n",
      "[81,     5] loss: 1.954\n",
      "[81,    10] loss: 1.955\n",
      "[81,    15] loss: 1.956\n",
      "Got 322 / 495 with accuracy 65.05\n",
      "[82,     5] loss: 1.953\n",
      "[82,    10] loss: 1.953\n",
      "[82,    15] loss: 1.953\n",
      "Got 327 / 495 with accuracy 66.06\n",
      "[83,     5] loss: 1.955\n",
      "[83,    10] loss: 1.954\n",
      "[83,    15] loss: 1.958\n",
      "Got 307 / 495 with accuracy 62.02\n",
      "[84,     5] loss: 1.957\n",
      "[84,    10] loss: 1.953\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-4d8c64399b0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# print statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# print every 2000 mini-batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             print('[%d, %5d] loss: %.3f' %\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#wandb.watch(model)\n",
    "for epoch in range(config.epochs):  # loop over the dataset multiple times\n",
    "    \n",
    "    #Training loop============================================\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        depth_images = data['depth_images']\n",
    "        labels = data['labels']\n",
    "\n",
    "        depth_images = depth_images.to(device=device)\n",
    "        labels = labels.to(device=device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(depth_images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 5 == 4:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2))\n",
    "            running_loss = 0.0\n",
    "                \n",
    "    #Test loop================================================\n",
    "    num_train_correct = 0\n",
    "    num_train_samples = 0\n",
    "    \n",
    "    num_val_correct = 0\n",
    "    num_val_samples = 0\n",
    "    \n",
    "    running_train_loss = 0\n",
    "    running_val_loss = 0\n",
    "    \n",
    "    model.eval()  \n",
    "    with torch.no_grad():\n",
    "        #Train set eval==============\n",
    "        for data in train_loader:\n",
    "            depth_images = data['depth_images']\n",
    "            labels = data['labels']\n",
    "\n",
    "            depth_images = depth_images.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "            \n",
    "            scores = model(depth_images)\n",
    "            _, predictions = scores.max(1)\n",
    "            num_train_correct += (predictions == labels).sum()\n",
    "            num_train_samples += predictions.size(0)\n",
    "            \n",
    "            running_train_loss += loss_fn(scores, labels)\n",
    "        \n",
    "        train_acc = float(num_train_correct)/float(num_train_samples)\n",
    "        train_loss = running_train_loss/len(validation_loader)\n",
    "        \n",
    "        #Test set eval===============\n",
    "        for data in validation_loader:\n",
    "            depth_images = data['depth_images']\n",
    "            labels = data['labels']\n",
    "\n",
    "            depth_images = depth_images.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "            \n",
    "            scores = model(depth_images)\n",
    "            _, predictions = scores.max(1)\n",
    "            num_val_correct += (predictions == labels).sum()\n",
    "            num_val_samples += predictions.size(0)\n",
    "            \n",
    "            running_val_loss += loss_fn(scores, labels)\n",
    "        \n",
    "        val_acc = float(num_val_correct)/float(num_val_samples)\n",
    "        val_loss = running_val_loss/len(validation_loader)\n",
    "        \n",
    "        print(f'Got {num_val_correct} / {num_val_samples} with accuracy {val_acc*100:.2f}')\n",
    "        \n",
    "        wandb.log({\n",
    "            \"Train Loss\":train_loss,\n",
    "            \"Validation Loss\":val_loss,\n",
    "            \"Train Accuracy\":train_acc,\n",
    "            \"Validation Accuracy\":val_acc\n",
    "            })\n",
    "        \n",
    "\n",
    "print('Finished Training')\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e67118b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trees_data.__getitem__(1)[\"depth_images\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b579ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
