{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d0eda33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import copy\n",
    "pdir = os.path.dirname(os.getcwd())\n",
    "sys.path.append(pdir)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, WeightedRandomSampler\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import utils\n",
    "from simpleview_pytorch import SimpleView\n",
    "\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "model_dir = 'models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e81a49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmja2106\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea303145",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd457ca",
   "metadata": {},
   "source": [
    "### Load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81f47d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEFAG     1116\n",
      "PINNIG      581\n",
      "QUEILE      364\n",
      "PINSYL      277\n",
      "PINPIN      140\n",
      "NA            2\n",
      "JUNIPE        2\n",
      "QUERCUS       2\n",
      "DEAD          1\n",
      "Name: sp, dtype: int64\n",
      "Species:  ['DEAD', 'JUNIPE', 'NA', 'PINNIG', 'PINPIN', 'PINSYL', 'QUEFAG', 'QUEILE', 'QUERCUS']\n",
      "Labels:  tensor([8, 3, 6,  ..., 7, 3, 6])\n",
      "Total count:  2485\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'tree_points.pt'\n",
    "\n",
    "trees_data = torch.load(dataset_name)\n",
    "val_data = torch.load(dataset_name)\n",
    "print(trees_data.counts)\n",
    "print('Species: ', trees_data.species)\n",
    "print('Labels: ', trees_data.labels)\n",
    "print('Total count: ', len(trees_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a894b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.30 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.15<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">cosmic-dawn-87</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mja2106/laser-trees\" target=\"_blank\">https://wandb.ai/mja2106/laser-trees</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/mja2106/laser-trees/runs/3o0afc4d\" target=\"_blank\">https://wandb.ai/mja2106/laser-trees/runs/3o0afc4d</a><br/>\n",
       "                Run data is saved locally in <code>/home/matt/Work/MRes-Project/laser-trees/notebooks/wandb/run-20210524_152744-3o0afc4d</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = {\n",
    "    \"dataset_type\":type(trees_data),\n",
    "    \"batch_size\":128,\n",
    "    \"validation_split\":.2,\n",
    "    \"shuffle_dataset\":True,\n",
    "    \"random_seed\":0,\n",
    "    \"learning_rate\":[0.0005, 100, 0.5],  #[init, step_size, gamma] for scheduler\n",
    "    \"momentum\":0.9, #Only used for sgd\n",
    "    \"epochs\":300,\n",
    "    \"loss_fn\":\"cross-entropy\",\n",
    "    \"optimizer\":\"adam\",\n",
    "    \"voting\":\"None\",\n",
    "    \"train_sampler\":\"balanced\",\n",
    "    \n",
    "    \"model\":\"SimpleView\",\n",
    "    \n",
    "    \"image_dim\":trees_data.image_dim,\n",
    "    \"camera_fov_deg\":trees_data.camera_fov_deg,\n",
    "    \"f\":trees_data.f,\n",
    "    \"camera_dist\":trees_data.camera_dist,\n",
    "    \"depth_averaging\":\"min\",\n",
    "    \n",
    "    \"transforms\":['rotation','translation','jitter'], #,'translation'\n",
    "    \"min_rotation\":0,\n",
    "    \"max_rotation\":2*np.pi,\n",
    "    \"min_translation\":0,\n",
    "    \"max_translation\":0.5,\n",
    "    \"jitter_std\":3e-4, \n",
    "    \n",
    "    \"species\":[\"QUEFAG\", \"PINNIG\", \"QUEILE\", \"PINSYL\", \"PINPIN\"],\n",
    "    \"data_resolution\":\"2.5cm\"\n",
    "}\n",
    "\n",
    "\n",
    "if params[\"dataset_type\"] == utils.dataset.TreeSpeciesPointDataset: #Change these by hand using point dataset\n",
    "    params[\"image_dim\"] = 256\n",
    "    params[\"camera_fov_deg\"] = 90 \n",
    "    params[\"f\"] = 1\n",
    "    params[\"camera_dist\"] = 1.4\n",
    "    params[\"depth_averaging\"] = \"min\"\n",
    "    params[\"soft_min_k\"] = 50\n",
    "    params[\"num_views\"] = 6\n",
    "    \n",
    "    trees_data.set_params(image_dim = params[\"image_dim\"],\n",
    "                         camera_fov_deg = params[\"camera_fov_deg\"],\n",
    "                         f = params[\"f\"],\n",
    "                         camera_dist = params[\"camera_dist\"],\n",
    "                         soft_min_k = params[\"soft_min_k\"],\n",
    "                         transforms = params[\"transforms\"],\n",
    "                         min_rotation = params[\"min_rotation\"],\n",
    "                         max_rotation = params[\"max_rotation\"],\n",
    "                         min_translation = params[\"min_translation\"],\n",
    "                         max_translation = params[\"max_translation\"],\n",
    "                         jitter_std = params[\"jitter_std\"]\n",
    "                         )\n",
    "    \n",
    "    val_data.set_params(image_dim = params[\"image_dim\"],\n",
    "                         camera_fov_deg = params[\"camera_fov_deg\"],\n",
    "                         f = params[\"f\"],\n",
    "                         camera_dist = params[\"camera_dist\"],\n",
    "                         soft_min_k = params[\"soft_min_k\"],\n",
    "                         transforms = params[\"transforms\"],\n",
    "                         min_rotation = params[\"min_rotation\"],\n",
    "                         max_rotation = params[\"max_rotation\"],\n",
    "                         min_translation = params[\"min_translation\"],\n",
    "                         max_translation = params[\"max_translation\"],\n",
    "                         jitter_std = params[\"jitter_std\"]\n",
    "                         )\n",
    "    \n",
    "elif params[\"dataset_type\"] == utils.dataset.TreeSpeciesDataset:\n",
    "    params[\"image_dim\"] = trees_data.image_dim\n",
    "    params[\"camera_fov_deg\"] = trees_data.camera_fov_deg\n",
    "    params[\"f\"] = trees_data.f\n",
    "    params[\"camera_dist\"] = trees_data.camera_dist\n",
    "    params[\"num_views\"] = trees_data.depth_images.shape[1]\n",
    "    params[\"depth_averaging\"] = \"min\"\n",
    "\n",
    "    \n",
    "if trees_data.soft_min_k:\n",
    "    params[\"soft_min_k\"] = trees_data.soft_min_k\n",
    "\n",
    "experiment_name = wandb.util.generate_id()\n",
    "    \n",
    "run = wandb.init(\n",
    "    project='laser-trees',\n",
    "    group=experiment_name,\n",
    "    config=params)    \n",
    "\n",
    "config = wandb.config\n",
    "torch.manual_seed(config.random_seed)\n",
    "torch.cuda.manual_seed(config.random_seed)\n",
    "np.random.seed(config.random_seed)\n",
    "random.seed(config.random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950e42c7",
   "metadata": {},
   "source": [
    "#### Remove low-count species:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7da3f8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing: NA\n",
      "Removing: QUERCUS\n",
      "Removing: DEAD\n",
      "Removing: JUNIPE\n",
      "Train Dataset:\n",
      "QUEFAG    1116\n",
      "PINNIG     581\n",
      "QUEILE     364\n",
      "PINSYL     277\n",
      "PINPIN     140\n",
      "Name: sp, dtype: int64\n",
      "Species:  ['PINNIG', 'PINPIN', 'PINSYL', 'QUEFAG', 'QUEILE']\n",
      "Labels:  tensor([0, 3, 3,  ..., 4, 0, 3])\n",
      "Total count:  2478\n",
      "\n",
      "Validation Dataset (should match):\n",
      "QUEFAG    1116\n",
      "PINNIG     581\n",
      "QUEILE     364\n",
      "PINSYL     277\n",
      "PINPIN     140\n",
      "Name: sp, dtype: int64\n",
      "Species:  ['PINNIG', 'PINPIN', 'PINSYL', 'QUEFAG', 'QUEILE']\n",
      "Labels:  tensor([0, 3, 3,  ..., 4, 0, 3])\n",
      "Total count:  2478\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for specie in list(set(trees_data.species) - set(config.species)):\n",
    "    print(\"Removing: {}\".format(specie))\n",
    "    trees_data.remove_species(specie)\n",
    "    val_data.remove_species(specie)\n",
    "\n",
    "print('Train Dataset:')\n",
    "print(trees_data.counts)\n",
    "print('Species: ', trees_data.species)\n",
    "print('Labels: ', trees_data.labels)\n",
    "print('Total count: ', len(trees_data))\n",
    "print()\n",
    "\n",
    "print('Validation Dataset (should match):')\n",
    "print(val_data.counts)\n",
    "print('Species: ', val_data.species)\n",
    "print('Labels: ', val_data.labels)\n",
    "print('Total count: ', len(val_data))\n",
    "print()\n",
    "\n",
    "assert len(val_data) == len(trees_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ad62eb",
   "metadata": {},
   "source": [
    "#### Train-validation split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f21d506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling dataset...\n"
     ]
    }
   ],
   "source": [
    "dataset_size = len(trees_data)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(config.validation_split * dataset_size))\n",
    "\n",
    "if config.shuffle_dataset :\n",
    "    print(\"Shuffling dataset...\")\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd8e3569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using balanced sampling...\n"
     ]
    }
   ],
   "source": [
    "#Train sampler==========================================\n",
    "if config.train_sampler == \"random\": \n",
    "    print(\"Using random/uniform sampling...\")\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "elif config.train_sampler == \"balanced\":\n",
    "    print(\"Using balanced sampling...\")\n",
    "    labels = trees_data.labels[train_indices] #Counts over \n",
    "    counts = torch.bincount(labels) #Training set only\n",
    "    label_weights = 1 / counts \n",
    "    \n",
    "    sample_weights = torch.stack([label_weights[label] for label in trees_data.labels]) #Corresponding weight for each sample\n",
    "    sample_weights[val_indices] = 0 #Never sample the validation dataset - set weights to zero\n",
    "    \n",
    "    train_sampler = WeightedRandomSampler(sample_weights, len(sample_weights))\n",
    "#=======================================================    \n",
    "    \n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trees_data, batch_size=config.batch_size, \n",
    "                                           sampler=train_sampler)\n",
    "\n",
    "val_data.set_params(transforms=['none']) #Turn off transforms for the validation dataset - DON'T GIVE IT AN EMPTY LIST\n",
    "validation_loader = torch.utils.data.DataLoader(val_data, batch_size=config.batch_size,\n",
    "                                                sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c211c921",
   "metadata": {},
   "outputs": [],
   "source": [
    "if None:\n",
    "    labels = trees_data.labels[train_indices] #Counts over \n",
    "    counts = torch.bincount(labels) #Training set only\n",
    "    label_weights = 1 / counts\n",
    "\n",
    "    sample_weights = torch.stack([label_weights[label] for label in trees_data.labels])\n",
    "    sample_weights[val_indices] = 0\n",
    "    print(label_weights)\n",
    "    print(len(trees_data.labels))\n",
    "    print(sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b1e3586",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run to print no. instances of each class\n",
    "if None:\n",
    "    for x in train_loader:\n",
    "        print(torch.unique(x['labels'], return_counts = True))\n",
    "    print()\n",
    "\n",
    "    for x in validation_loader:\n",
    "        print(torch.unique(x['labels'], return_counts = True))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281e9050",
   "metadata": {},
   "source": [
    "### Define model, loss fn, optimiser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "116533cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cross-entropy loss...\n",
      "Optimizing with AdaM...\n",
      "Using step LR scheduler...\n"
     ]
    }
   ],
   "source": [
    "assert set(config.species) == set(trees_data.species)\n",
    "\n",
    "if config.model==\"SimpleView\":\n",
    "    model = SimpleView(\n",
    "        num_views=config.num_views,\n",
    "        num_classes=len(config.species)\n",
    "    )\n",
    "\n",
    "model = model.to(device=device)\n",
    "\n",
    "if config.loss_fn==\"cross-entropy\":\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    print(\"Using cross-entropy loss...\")\n",
    "if config.loss_fn==\"smooth-loss\":\n",
    "    loss_fn = utils.smooth_loss\n",
    "    print(\"Using smooth-loss\")\n",
    "    \n",
    "if type(config.learning_rate) == list:\n",
    "    lr = config.learning_rate[0]\n",
    "    step_size = config.learning_rate[1]\n",
    "    gamma = config.learning_rate[2]\n",
    "else:\n",
    "    lr = config.learning_rate\n",
    "    \n",
    "if config.optimizer==\"sgd\":\n",
    "    print(\"Optimizing with SGD...\")\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=config.momentum)\n",
    "elif config.optimizer==\"adam\":\n",
    "    print(\"Optimizing with AdaM...\")\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "if type(config.learning_rate) == list:\n",
    "    print(\"Using step LR scheduler...\")\n",
    "    scheduler = StepLR(optimizer, step_size=step_size, gamma=gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868ee1f0",
   "metadata": {},
   "source": [
    "### Train & Test Loops:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3905ae3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     5] loss: 3.733\n",
      "[1,    10] loss: 3.526\n",
      "[1,    15] loss: 3.532\n",
      "[1,    20] loss: 3.586\n",
      "OVERALL: Got 42 / 495 with accuracy 8.48\n",
      "PINNIG: Got 0/129 with accuracy 0.00\n",
      "PINPIN: Got 0/33 with accuracy 0.00\n",
      "PINSYL: Got 42/42 with accuracy 100.00\n",
      "QUEFAG: Got 0/231 with accuracy 0.00\n",
      "QUEILE: Got 0/60 with accuracy 0.00\n",
      "[2,     5] loss: 3.335\n",
      "[2,    10] loss: 3.296\n",
      "[2,    15] loss: 3.338\n",
      "[2,    20] loss: 3.169\n",
      "OVERALL: Got 58 / 495 with accuracy 11.72\n",
      "PINNIG: Got 0/129 with accuracy 0.00\n",
      "PINPIN: Got 0/33 with accuracy 0.00\n",
      "PINSYL: Got 39/42 with accuracy 92.86\n",
      "QUEFAG: Got 15/231 with accuracy 6.49\n",
      "QUEILE: Got 4/60 with accuracy 6.67\n",
      "[3,     5] loss: 3.091\n",
      "[3,    10] loss: 3.017\n",
      "[3,    15] loss: 2.936\n",
      "[3,    20] loss: 2.891\n",
      "OVERALL: Got 78 / 495 with accuracy 15.76\n",
      "PINNIG: Got 1/129 with accuracy 0.78\n",
      "PINPIN: Got 0/33 with accuracy 0.00\n",
      "PINSYL: Got 40/42 with accuracy 95.24\n",
      "QUEFAG: Got 1/231 with accuracy 0.43\n",
      "QUEILE: Got 36/60 with accuracy 60.00\n",
      "[4,     5] loss: 2.914\n",
      "[4,    10] loss: 2.908\n",
      "[4,    15] loss: 2.911\n",
      "[4,    20] loss: 2.883\n",
      "OVERALL: Got 258 / 495 with accuracy 52.12\n",
      "PINNIG: Got 24/129 with accuracy 18.60\n",
      "PINPIN: Got 6/33 with accuracy 18.18\n",
      "PINSYL: Got 27/42 with accuracy 64.29\n",
      "QUEFAG: Got 159/231 with accuracy 68.83\n",
      "QUEILE: Got 42/60 with accuracy 70.00\n",
      "[5,     5] loss: 2.706\n",
      "[5,    10] loss: 2.692\n",
      "[5,    15] loss: 2.734\n",
      "[5,    20] loss: 2.909\n",
      "OVERALL: Got 259 / 495 with accuracy 52.32\n",
      "PINNIG: Got 91/129 with accuracy 70.54\n",
      "PINPIN: Got 0/33 with accuracy 0.00\n",
      "PINSYL: Got 17/42 with accuracy 40.48\n",
      "QUEFAG: Got 107/231 with accuracy 46.32\n",
      "QUEILE: Got 44/60 with accuracy 73.33\n",
      "[6,     5] loss: 2.767\n",
      "[6,    10] loss: 2.741\n",
      "[6,    15] loss: 2.570\n",
      "[6,    20] loss: 2.691\n",
      "OVERALL: Got 341 / 495 with accuracy 68.89\n",
      "PINNIG: Got 101/129 with accuracy 78.29\n",
      "PINPIN: Got 1/33 with accuracy 3.03\n",
      "PINSYL: Got 0/42 with accuracy 0.00\n",
      "QUEFAG: Got 211/231 with accuracy 91.34\n",
      "QUEILE: Got 28/60 with accuracy 46.67\n",
      "[7,     5] loss: 2.783\n",
      "[7,    10] loss: 2.705\n",
      "[7,    15] loss: 2.705\n",
      "[7,    20] loss: 2.606\n",
      "OVERALL: Got 181 / 495 with accuracy 36.57\n",
      "PINNIG: Got 111/129 with accuracy 86.05\n",
      "PINPIN: Got 0/33 with accuracy 0.00\n",
      "PINSYL: Got 11/42 with accuracy 26.19\n",
      "QUEFAG: Got 20/231 with accuracy 8.66\n",
      "QUEILE: Got 39/60 with accuracy 65.00\n",
      "[8,     5] loss: 2.710\n",
      "[8,    10] loss: 2.631\n",
      "[8,    15] loss: 2.643\n",
      "[8,    20] loss: 2.574\n",
      "OVERALL: Got 328 / 495 with accuracy 66.26\n",
      "PINNIG: Got 79/129 with accuracy 61.24\n",
      "PINPIN: Got 4/33 with accuracy 12.12\n",
      "PINSYL: Got 13/42 with accuracy 30.95\n",
      "QUEFAG: Got 185/231 with accuracy 80.09\n",
      "QUEILE: Got 47/60 with accuracy 78.33\n",
      "[9,     5] loss: 2.593\n",
      "[9,    10] loss: 2.439\n",
      "[9,    15] loss: 2.608\n",
      "[9,    20] loss: 2.526\n",
      "OVERALL: Got 249 / 495 with accuracy 50.30\n",
      "PINNIG: Got 91/129 with accuracy 70.54\n",
      "PINPIN: Got 7/33 with accuracy 21.21\n",
      "PINSYL: Got 11/42 with accuracy 26.19\n",
      "QUEFAG: Got 86/231 with accuracy 37.23\n",
      "QUEILE: Got 54/60 with accuracy 90.00\n",
      "[10,     5] loss: 2.510\n",
      "[10,    10] loss: 2.340\n",
      "[10,    15] loss: 2.458\n",
      "[10,    20] loss: 2.521\n",
      "OVERALL: Got 254 / 495 with accuracy 51.31\n",
      "PINNIG: Got 90/129 with accuracy 69.77\n",
      "PINPIN: Got 6/33 with accuracy 18.18\n",
      "PINSYL: Got 14/42 with accuracy 33.33\n",
      "QUEFAG: Got 90/231 with accuracy 38.96\n",
      "QUEILE: Got 54/60 with accuracy 90.00\n",
      "[11,     5] loss: 2.542\n",
      "[11,    10] loss: 2.491\n",
      "[11,    15] loss: 2.477\n",
      "[11,    20] loss: 2.470\n",
      "OVERALL: Got 148 / 495 with accuracy 29.90\n",
      "PINNIG: Got 54/129 with accuracy 41.86\n",
      "PINPIN: Got 4/33 with accuracy 12.12\n",
      "PINSYL: Got 29/42 with accuracy 69.05\n",
      "QUEFAG: Got 35/231 with accuracy 15.15\n",
      "QUEILE: Got 26/60 with accuracy 43.33\n",
      "[12,     5] loss: 2.383\n",
      "[12,    10] loss: 2.248\n",
      "[12,    15] loss: 2.354\n",
      "[12,    20] loss: 2.413\n",
      "OVERALL: Got 99 / 495 with accuracy 20.00\n",
      "PINNIG: Got 1/129 with accuracy 0.78\n",
      "PINPIN: Got 30/33 with accuracy 90.91\n",
      "PINSYL: Got 14/42 with accuracy 33.33\n",
      "QUEFAG: Got 33/231 with accuracy 14.29\n",
      "QUEILE: Got 21/60 with accuracy 35.00\n",
      "[13,     5] loss: 2.367\n",
      "[13,    10] loss: 2.271\n",
      "[13,    15] loss: 2.224\n",
      "[13,    20] loss: 2.391\n",
      "OVERALL: Got 303 / 495 with accuracy 61.21\n",
      "PINNIG: Got 47/129 with accuracy 36.43\n",
      "PINPIN: Got 20/33 with accuracy 60.61\n",
      "PINSYL: Got 19/42 with accuracy 45.24\n",
      "QUEFAG: Got 188/231 with accuracy 81.39\n",
      "QUEILE: Got 29/60 with accuracy 48.33\n",
      "[14,     5] loss: 2.268\n",
      "[14,    10] loss: 2.309\n",
      "[14,    15] loss: 2.212\n",
      "[14,    20] loss: 2.245\n",
      "OVERALL: Got 225 / 495 with accuracy 45.45\n",
      "PINNIG: Got 67/129 with accuracy 51.94\n",
      "PINPIN: Got 17/33 with accuracy 51.52\n",
      "PINSYL: Got 18/42 with accuracy 42.86\n",
      "QUEFAG: Got 70/231 with accuracy 30.30\n",
      "QUEILE: Got 53/60 with accuracy 88.33\n",
      "[15,     5] loss: 2.366\n",
      "[15,    10] loss: 2.228\n",
      "[15,    15] loss: 2.215\n",
      "[15,    20] loss: 2.086\n",
      "OVERALL: Got 267 / 495 with accuracy 53.94\n",
      "PINNIG: Got 48/129 with accuracy 37.21\n",
      "PINPIN: Got 1/33 with accuracy 3.03\n",
      "PINSYL: Got 7/42 with accuracy 16.67\n",
      "QUEFAG: Got 155/231 with accuracy 67.10\n",
      "QUEILE: Got 56/60 with accuracy 93.33\n",
      "[16,     5] loss: 2.148\n",
      "[16,    10] loss: 2.121\n",
      "[16,    15] loss: 2.218\n",
      "[16,    20] loss: 2.142\n",
      "OVERALL: Got 308 / 495 with accuracy 62.22\n",
      "PINNIG: Got 46/129 with accuracy 35.66\n",
      "PINPIN: Got 29/33 with accuracy 87.88\n",
      "PINSYL: Got 8/42 with accuracy 19.05\n",
      "QUEFAG: Got 175/231 with accuracy 75.76\n",
      "QUEILE: Got 50/60 with accuracy 83.33\n",
      "[17,     5] loss: 2.273\n",
      "[17,    10] loss: 2.145\n",
      "[17,    15] loss: 2.141\n",
      "[17,    20] loss: 1.995\n",
      "OVERALL: Got 268 / 495 with accuracy 54.14\n",
      "PINNIG: Got 12/129 with accuracy 9.30\n",
      "PINPIN: Got 31/33 with accuracy 93.94\n",
      "PINSYL: Got 9/42 with accuracy 21.43\n",
      "QUEFAG: Got 165/231 with accuracy 71.43\n",
      "QUEILE: Got 51/60 with accuracy 85.00\n",
      "[18,     5] loss: 2.205\n",
      "[18,    10] loss: 1.980\n",
      "[18,    15] loss: 2.066\n",
      "[18,    20] loss: 2.114\n",
      "OVERALL: Got 337 / 495 with accuracy 68.08\n",
      "PINNIG: Got 97/129 with accuracy 75.19\n",
      "PINPIN: Got 10/33 with accuracy 30.30\n",
      "PINSYL: Got 9/42 with accuracy 21.43\n",
      "QUEFAG: Got 177/231 with accuracy 76.62\n",
      "QUEILE: Got 44/60 with accuracy 73.33\n",
      "[19,     5] loss: 2.148\n",
      "[19,    10] loss: 2.048\n",
      "[19,    15] loss: 1.980\n",
      "[19,    20] loss: 2.012\n",
      "OVERALL: Got 281 / 495 with accuracy 56.77\n",
      "PINNIG: Got 5/129 with accuracy 3.88\n",
      "PINPIN: Got 7/33 with accuracy 21.21\n",
      "PINSYL: Got 14/42 with accuracy 33.33\n",
      "QUEFAG: Got 227/231 with accuracy 98.27\n",
      "QUEILE: Got 28/60 with accuracy 46.67\n",
      "[20,     5] loss: 2.047\n",
      "[20,    10] loss: 2.057\n",
      "[20,    15] loss: 2.027\n",
      "[20,    20] loss: 2.041\n",
      "OVERALL: Got 316 / 495 with accuracy 63.84\n",
      "PINNIG: Got 98/129 with accuracy 75.97\n",
      "PINPIN: Got 16/33 with accuracy 48.48\n",
      "PINSYL: Got 13/42 with accuracy 30.95\n",
      "QUEFAG: Got 148/231 with accuracy 64.07\n",
      "QUEILE: Got 41/60 with accuracy 68.33\n",
      "[21,     5] loss: 1.925\n"
     ]
    }
   ],
   "source": [
    "#wandb.watch(model)\n",
    "best_acc = 0\n",
    "for epoch in range(config.epochs):  # loop over the dataset multiple times\n",
    "    \n",
    "    #Training loop============================================\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        depth_images = data['depth_images']\n",
    "        labels = data['labels']\n",
    "\n",
    "        depth_images = depth_images.to(device=device)\n",
    "        labels = labels.to(device=device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(depth_images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 5 == 4:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2))\n",
    "            running_loss = 0.0\n",
    "                \n",
    "    #Test loop================================================\n",
    "    num_train_correct = 0\n",
    "    num_train_samples = 0\n",
    "    \n",
    "    num_val_correct = 0\n",
    "    num_val_samples = 0\n",
    "    \n",
    "    running_train_loss = 0\n",
    "    running_val_loss = 0\n",
    "    \n",
    "    model.eval()  \n",
    "    with torch.no_grad():\n",
    "        #Train set eval==============\n",
    "        for data in train_loader:\n",
    "            depth_images = data['depth_images']\n",
    "            labels = data['labels']\n",
    "\n",
    "            depth_images = depth_images.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "            \n",
    "            scores = model(depth_images)\n",
    "            _, predictions = scores.max(1)\n",
    "            num_train_correct += (predictions == labels).sum()\n",
    "            num_train_samples += predictions.size(0)\n",
    "            \n",
    "            running_train_loss += loss_fn(scores, labels)\n",
    "        \n",
    "        train_acc = float(num_train_correct)/float(num_train_samples)\n",
    "        train_loss = running_train_loss/len(validation_loader)\n",
    "        \n",
    "        \n",
    "        #Test set eval===============\n",
    "        all_labels = torch.tensor([]).to(device)\n",
    "        all_predictions = torch.tensor([]).to(device)\n",
    "        \n",
    "        for data in validation_loader:\n",
    "            depth_images = data['depth_images']\n",
    "            labels = data['labels']\n",
    "\n",
    "            depth_images = depth_images.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "            \n",
    "            scores = model(depth_images)\n",
    "            _, predictions = scores.max(1)\n",
    "            \n",
    "            all_labels = torch.cat((all_labels, labels))\n",
    "            all_predictions = torch.cat((all_predictions, predictions))\n",
    "            \n",
    "            num_val_correct += (predictions == labels).sum()\n",
    "            num_val_samples += predictions.size(0)\n",
    "            \n",
    "            running_val_loss += loss_fn(scores, labels)\n",
    "        \n",
    "        val_acc = float(num_val_correct)/float(num_val_samples)\n",
    "        val_loss = running_val_loss/len(validation_loader)\n",
    "        \n",
    "        print(f'OVERALL: Got {num_val_correct} / {num_val_samples} with accuracy {val_acc*100:.2f}')\n",
    "        \n",
    "        cm = confusion_matrix(all_labels.cpu(), all_predictions.cpu())\n",
    "        totals = cm.sum(axis=1)\n",
    "        \n",
    "        for i in range(len(totals)):\n",
    "            print(f\"{trees_data.species[i]}: Got {cm[i,i]}/{totals[i]} with accuracy {(cm[i,i]/totals[i])*100:.2f}\")\n",
    "            wandb.log({f\"{trees_data.species[i]} Accuracy\":(cm[i,i]/totals[i])}, commit = False)\n",
    "        \n",
    "        \n",
    "        if val_acc > best_acc:\n",
    "            best_model_state = copy.deepcopy(model.state_dict())\n",
    "            best_acc = val_acc\n",
    "        \n",
    "        wandb.log({\n",
    "            \"Train Loss\":train_loss,\n",
    "            \"Validation Loss\":val_loss,\n",
    "            \"Train Accuracy\":train_acc,\n",
    "            \"Validation Accuracy\":val_acc,\n",
    "            \"Learning Rate\":optimizer.param_groups[0]['lr']\n",
    "            })\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "print('Saving best model...')\n",
    "torch.save(best_model_state,\n",
    "           '{model_dir}/{fname}.pt'.format(\n",
    "               model_dir=model_dir,\n",
    "               fname=experiment_name+'_best.pt')\n",
    "          )\n",
    "print('Saved!')\n",
    "\n",
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
