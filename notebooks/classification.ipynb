{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68231fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "pdir = os.path.dirname(os.getcwd())\n",
    "sys.path.append(pdir)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import utils\n",
    "from simpleview_pytorch import SimpleView\n",
    "\n",
    "from torch.utils.data.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e3b20d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44d038d",
   "metadata": {},
   "source": [
    "### Load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac9b1bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEFAG     1116\n",
      "PINNIG      581\n",
      "QUEILE      364\n",
      "PINSYL      277\n",
      "PINPIN      140\n",
      "QUERCUS       2\n",
      "JUNIPE        2\n",
      "NA            2\n",
      "DEAD          1\n",
      "Name: sp, dtype: int64\n",
      "Species:  ['DEAD', 'JUNIPE', 'NA', 'PINNIG', 'PINPIN', 'PINSYL', 'QUEFAG', 'QUEILE', 'QUERCUS']\n",
      "Labels:  tensor([8, 3, 6,  ..., 7, 3, 6])\n",
      "Total count:  2485\n"
     ]
    }
   ],
   "source": [
    "trees_data = torch.load('trees_new.pt')\n",
    "print(trees_data.counts)\n",
    "print('Species: ', trees_data.species)\n",
    "print('Labels: ', trees_data.labels)\n",
    "print('Total count: ', len(trees_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b782619",
   "metadata": {},
   "source": [
    "#### Remove low-count species:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36e0f972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEFAG    1116\n",
      "PINNIG     581\n",
      "QUEILE     364\n",
      "PINSYL     277\n",
      "PINPIN     140\n",
      "Name: sp, dtype: int64\n",
      "Species:  ['PINNIG', 'PINPIN', 'PINSYL', 'QUEFAG', 'QUEILE']\n",
      "Labels:  tensor([0, 3, 3,  ..., 4, 0, 3])\n",
      "Total count:  2478\n"
     ]
    }
   ],
   "source": [
    "for specie in ['NA', 'QUERCUS', 'JUNIPE', 'DEAD']:\n",
    "    trees_data.remove_species(specie)\n",
    "    \n",
    "print(trees_data.counts)\n",
    "print('Species: ', trees_data.species)\n",
    "print('Labels: ', trees_data.labels)\n",
    "print('Total count: ', len(trees_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13d5e7e",
   "metadata": {},
   "source": [
    "#### Train-validation split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9bb8f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94218410",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(trees_data)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7e8d1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trees_data, batch_size=batch_size, \n",
    "                                           sampler=train_sampler)\n",
    "validation_loader = torch.utils.data.DataLoader(trees_data, batch_size=batch_size,\n",
    "                                                sampler=valid_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1301f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0, 1, 2, 3, 4]), tensor([28,  9, 21, 49, 21]))\n",
      "(tensor([0, 1, 2, 3, 4]), tensor([27,  5, 18, 59, 19]))\n",
      "(tensor([0, 1, 2, 3, 4]), tensor([38,  6, 12, 58, 14]))\n",
      "(tensor([0, 1, 2, 3, 4]), tensor([20, 16,  9, 62, 21]))\n",
      "(tensor([0, 1, 2, 3, 4]), tensor([28,  5, 16, 53, 26]))\n",
      "(tensor([0, 1, 2, 3, 4]), tensor([30,  9, 13, 59, 17]))\n",
      "(tensor([0, 1, 2, 3, 4]), tensor([27,  8, 15, 58, 20]))\n",
      "(tensor([0, 1, 2, 3, 4]), tensor([39,  6, 13, 47, 23]))\n",
      "(tensor([0, 1, 2, 3, 4]), tensor([24,  8, 15, 63, 18]))\n",
      "(tensor([0, 1, 2, 3, 4]), tensor([23,  2, 14, 71, 18]))\n",
      "(tensor([0, 1, 2, 3, 4]), tensor([34,  3, 20, 49, 22]))\n",
      "(tensor([0, 1, 2, 3, 4]), tensor([34,  8, 11, 52, 23]))\n",
      "(tensor([0, 1, 2, 3, 4]), tensor([34,  4, 20, 47, 23]))\n",
      "(tensor([0, 1, 2, 3, 4]), tensor([23,  4, 14, 76, 11]))\n",
      "(tensor([0, 1, 2, 3, 4]), tensor([27,  9, 17, 54, 21]))\n",
      "(tensor([0, 1, 2, 3, 4]), tensor([16,  5,  7, 28,  7]))\n",
      "\n",
      "(tensor([0, 1, 2, 3, 4]), tensor([32,  9, 12, 61, 14]))\n",
      "(tensor([0, 1, 2, 3, 4]), tensor([29,  9, 12, 62, 16]))\n",
      "(tensor([0, 1, 2, 3, 4]), tensor([34, 11, 10, 56, 17]))\n",
      "(tensor([0, 1, 2, 3, 4]), tensor([34,  4,  8, 52, 13]))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in train_loader:\n",
    "    print(torch.unique(x['labels'], return_counts = True))\n",
    "print()\n",
    "\n",
    "for x in validation_loader:\n",
    "    print(torch.unique(x['labels'], return_counts = True))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7d9977",
   "metadata": {},
   "source": [
    "### Define model, loss fn, optimiser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1fbd5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleView(\n",
    "    num_views=trees_data.depth_images.shape[1],\n",
    "    num_classes=len(trees_data.species)\n",
    ")\n",
    "\n",
    "model = model.to(device=device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0005, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8535e5ae",
   "metadata": {},
   "source": [
    "### Train & Test Loops:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17d9e942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     5] loss: 4.104\n",
      "[1,    10] loss: 3.582\n",
      "[1,    15] loss: 3.630\n",
      "Got 231 / 495 with accuracy 46.67\n",
      "[2,     5] loss: 3.320\n",
      "[2,    10] loss: 3.323\n",
      "[2,    15] loss: 3.313\n",
      "Got 141 / 495 with accuracy 28.48\n",
      "[3,     5] loss: 3.196\n",
      "[3,    10] loss: 3.149\n",
      "[3,    15] loss: 3.089\n",
      "Got 245 / 495 with accuracy 49.49\n",
      "[4,     5] loss: 3.072\n",
      "[4,    10] loss: 3.088\n",
      "[4,    15] loss: 3.024\n",
      "Got 280 / 495 with accuracy 56.57\n",
      "[5,     5] loss: 2.981\n",
      "[5,    10] loss: 2.954\n",
      "[5,    15] loss: 2.959\n",
      "Got 285 / 495 with accuracy 57.58\n",
      "[6,     5] loss: 2.891\n",
      "[6,    10] loss: 2.904\n",
      "[6,    15] loss: 2.910\n",
      "Got 278 / 495 with accuracy 56.16\n",
      "[7,     5] loss: 2.857\n",
      "[7,    10] loss: 2.806\n",
      "[7,    15] loss: 2.891\n",
      "Got 290 / 495 with accuracy 58.59\n",
      "[8,     5] loss: 2.743\n",
      "[8,    10] loss: 2.825\n",
      "[8,    15] loss: 2.856\n",
      "Got 290 / 495 with accuracy 58.59\n",
      "[9,     5] loss: 2.801\n",
      "[9,    10] loss: 2.810\n",
      "[9,    15] loss: 2.691\n",
      "Got 287 / 495 with accuracy 57.98\n",
      "[10,     5] loss: 2.837\n",
      "[10,    10] loss: 2.707\n",
      "[10,    15] loss: 2.650\n",
      "Got 291 / 495 with accuracy 58.79\n",
      "[11,     5] loss: 2.671\n",
      "[11,    10] loss: 2.666\n",
      "[11,    15] loss: 2.727\n",
      "Got 286 / 495 with accuracy 57.78\n",
      "[12,     5] loss: 2.763\n",
      "[12,    10] loss: 2.633\n",
      "[12,    15] loss: 2.564\n",
      "Got 296 / 495 with accuracy 59.80\n",
      "[13,     5] loss: 2.597\n",
      "[13,    10] loss: 2.689\n",
      "[13,    15] loss: 2.528\n",
      "Got 306 / 495 with accuracy 61.82\n",
      "[14,     5] loss: 2.559\n",
      "[14,    10] loss: 2.518\n",
      "[14,    15] loss: 2.643\n",
      "Got 303 / 495 with accuracy 61.21\n",
      "[15,     5] loss: 2.667\n",
      "[15,    10] loss: 2.558\n",
      "[15,    15] loss: 2.364\n",
      "Got 302 / 495 with accuracy 61.01\n",
      "[16,     5] loss: 2.549\n",
      "[16,    10] loss: 2.538\n",
      "[16,    15] loss: 2.432\n",
      "Got 310 / 495 with accuracy 62.63\n",
      "[17,     5] loss: 2.553\n",
      "[17,    10] loss: 2.497\n",
      "[17,    15] loss: 2.419\n",
      "Got 309 / 495 with accuracy 62.42\n",
      "[18,     5] loss: 2.525\n",
      "[18,    10] loss: 2.415\n",
      "[18,    15] loss: 2.416\n",
      "Got 309 / 495 with accuracy 62.42\n",
      "[19,     5] loss: 2.360\n",
      "[19,    10] loss: 2.448\n",
      "[19,    15] loss: 2.435\n",
      "Got 315 / 495 with accuracy 63.64\n",
      "[20,     5] loss: 2.387\n",
      "[20,    10] loss: 2.378\n",
      "[20,    15] loss: 2.411\n",
      "Got 313 / 495 with accuracy 63.23\n",
      "[21,     5] loss: 2.348\n",
      "[21,    10] loss: 2.362\n",
      "[21,    15] loss: 2.326\n",
      "Got 309 / 495 with accuracy 62.42\n",
      "[22,     5] loss: 2.295\n",
      "[22,    10] loss: 2.392\n",
      "[22,    15] loss: 2.359\n",
      "Got 312 / 495 with accuracy 63.03\n",
      "[23,     5] loss: 2.261\n",
      "[23,    10] loss: 2.400\n",
      "[23,    15] loss: 2.328\n",
      "Got 307 / 495 with accuracy 62.02\n",
      "[24,     5] loss: 2.351\n",
      "[24,    10] loss: 2.230\n",
      "[24,    15] loss: 2.257\n",
      "Got 311 / 495 with accuracy 62.83\n",
      "[25,     5] loss: 2.318\n",
      "[25,    10] loss: 2.349\n",
      "[25,    15] loss: 2.134\n",
      "Got 308 / 495 with accuracy 62.22\n",
      "[26,     5] loss: 2.438\n",
      "[26,    10] loss: 2.139\n",
      "[26,    15] loss: 2.155\n",
      "Got 313 / 495 with accuracy 63.23\n",
      "[27,     5] loss: 2.299\n",
      "[27,    10] loss: 2.213\n",
      "[27,    15] loss: 2.102\n",
      "Got 312 / 495 with accuracy 63.03\n",
      "[28,     5] loss: 2.117\n",
      "[28,    10] loss: 2.205\n",
      "[28,    15] loss: 2.277\n",
      "Got 311 / 495 with accuracy 62.83\n",
      "[29,     5] loss: 2.104\n",
      "[29,    10] loss: 2.221\n",
      "[29,    15] loss: 2.240\n",
      "Got 306 / 495 with accuracy 61.82\n",
      "[30,     5] loss: 2.253\n",
      "[30,    10] loss: 2.055\n",
      "[30,    15] loss: 2.150\n",
      "Got 314 / 495 with accuracy 63.43\n",
      "[31,     5] loss: 2.110\n",
      "[31,    10] loss: 2.119\n",
      "[31,    15] loss: 2.146\n",
      "Got 310 / 495 with accuracy 62.63\n",
      "[32,     5] loss: 2.157\n",
      "[32,    10] loss: 2.122\n",
      "[32,    15] loss: 2.040\n",
      "Got 312 / 495 with accuracy 63.03\n",
      "[33,     5] loss: 2.076\n",
      "[33,    10] loss: 2.154\n",
      "[33,    15] loss: 2.008\n",
      "Got 313 / 495 with accuracy 63.23\n",
      "[34,     5] loss: 1.995\n",
      "[34,    10] loss: 2.069\n",
      "[34,    15] loss: 2.056\n",
      "Got 311 / 495 with accuracy 62.83\n",
      "[35,     5] loss: 2.024\n",
      "[35,    10] loss: 2.145\n",
      "[35,    15] loss: 1.997\n",
      "Got 311 / 495 with accuracy 62.83\n",
      "[36,     5] loss: 2.054\n",
      "[36,    10] loss: 1.956\n",
      "[36,    15] loss: 2.041\n",
      "Got 307 / 495 with accuracy 62.02\n",
      "[37,     5] loss: 1.870\n",
      "[37,    10] loss: 2.135\n",
      "[37,    15] loss: 2.001\n",
      "Got 308 / 495 with accuracy 62.22\n",
      "[38,     5] loss: 1.917\n",
      "[38,    10] loss: 1.946\n",
      "[38,    15] loss: 2.069\n",
      "Got 304 / 495 with accuracy 61.41\n",
      "[39,     5] loss: 1.953\n",
      "[39,    10] loss: 1.996\n",
      "[39,    15] loss: 1.923\n",
      "Got 308 / 495 with accuracy 62.22\n",
      "[40,     5] loss: 1.910\n",
      "[40,    10] loss: 1.910\n",
      "[40,    15] loss: 1.983\n",
      "Got 304 / 495 with accuracy 61.41\n",
      "[41,     5] loss: 1.927\n",
      "[41,    10] loss: 1.887\n",
      "[41,    15] loss: 1.872\n",
      "Got 300 / 495 with accuracy 60.61\n",
      "[42,     5] loss: 1.893\n",
      "[42,    10] loss: 1.824\n",
      "[42,    15] loss: 1.948\n",
      "Got 309 / 495 with accuracy 62.42\n",
      "[43,     5] loss: 1.855\n",
      "[43,    10] loss: 1.897\n",
      "[43,    15] loss: 1.777\n",
      "Got 306 / 495 with accuracy 61.82\n",
      "[44,     5] loss: 1.812\n",
      "[44,    10] loss: 1.721\n",
      "[44,    15] loss: 1.918\n",
      "Got 304 / 495 with accuracy 61.41\n",
      "[45,     5] loss: 1.781\n",
      "[45,    10] loss: 1.733\n",
      "[45,    15] loss: 1.925\n",
      "Got 306 / 495 with accuracy 61.82\n",
      "[46,     5] loss: 1.847\n",
      "[46,    10] loss: 1.700\n",
      "[46,    15] loss: 1.756\n",
      "Got 309 / 495 with accuracy 62.42\n",
      "[47,     5] loss: 1.689\n",
      "[47,    10] loss: 1.749\n",
      "[47,    15] loss: 1.866\n",
      "Got 311 / 495 with accuracy 62.83\n",
      "[48,     5] loss: 1.816\n",
      "[48,    10] loss: 1.710\n",
      "[48,    15] loss: 1.687\n",
      "Got 311 / 495 with accuracy 62.83\n",
      "[49,     5] loss: 1.621\n",
      "[49,    10] loss: 1.675\n",
      "[49,    15] loss: 1.804\n",
      "Got 313 / 495 with accuracy 63.23\n",
      "[50,     5] loss: 1.764\n",
      "[50,    10] loss: 1.668\n",
      "[50,    15] loss: 1.677\n",
      "Got 311 / 495 with accuracy 62.83\n",
      "[51,     5] loss: 1.698\n",
      "[51,    10] loss: 1.730\n",
      "[51,    15] loss: 1.580\n",
      "Got 314 / 495 with accuracy 63.43\n",
      "[52,     5] loss: 1.606\n",
      "[52,    10] loss: 1.692\n",
      "[52,    15] loss: 1.592\n",
      "Got 312 / 495 with accuracy 63.03\n",
      "[53,     5] loss: 1.615\n",
      "[53,    10] loss: 1.552\n",
      "[53,    15] loss: 1.681\n",
      "Got 314 / 495 with accuracy 63.43\n",
      "[54,     5] loss: 1.614\n",
      "[54,    10] loss: 1.534\n",
      "[54,    15] loss: 1.605\n",
      "Got 307 / 495 with accuracy 62.02\n",
      "[55,     5] loss: 1.695\n",
      "[55,    10] loss: 1.540\n",
      "[55,    15] loss: 1.520\n",
      "Got 312 / 495 with accuracy 63.03\n",
      "[56,     5] loss: 1.631\n",
      "[56,    10] loss: 1.442\n",
      "[56,    15] loss: 1.555\n",
      "Got 309 / 495 with accuracy 62.42\n",
      "[57,     5] loss: 1.550\n",
      "[57,    10] loss: 1.483\n",
      "[57,    15] loss: 1.548\n",
      "Got 312 / 495 with accuracy 63.03\n",
      "[58,     5] loss: 1.510\n",
      "[58,    10] loss: 1.469\n",
      "[58,    15] loss: 1.510\n",
      "Got 311 / 495 with accuracy 62.83\n",
      "[59,     5] loss: 1.434\n",
      "[59,    10] loss: 1.519\n",
      "[59,    15] loss: 1.442\n",
      "Got 310 / 495 with accuracy 62.63\n",
      "[60,     5] loss: 1.446\n",
      "[60,    10] loss: 1.451\n",
      "[60,    15] loss: 1.413\n",
      "Got 308 / 495 with accuracy 62.22\n",
      "[61,     5] loss: 1.387\n",
      "[61,    10] loss: 1.454\n",
      "[61,    15] loss: 1.401\n",
      "Got 314 / 495 with accuracy 63.43\n",
      "[62,     5] loss: 1.368\n",
      "[62,    10] loss: 1.366\n",
      "[62,    15] loss: 1.407\n",
      "Got 312 / 495 with accuracy 63.03\n",
      "[63,     5] loss: 1.310\n",
      "[63,    10] loss: 1.365\n",
      "[63,    15] loss: 1.417\n",
      "Got 311 / 495 with accuracy 62.83\n",
      "[64,     5] loss: 1.360\n",
      "[64,    10] loss: 1.280\n",
      "[64,    15] loss: 1.356\n",
      "Got 309 / 495 with accuracy 62.42\n",
      "[65,     5] loss: 1.324\n",
      "[65,    10] loss: 1.285\n",
      "[65,    15] loss: 1.275\n",
      "Got 311 / 495 with accuracy 62.83\n",
      "[66,     5] loss: 1.323\n",
      "[66,    10] loss: 1.241\n",
      "[66,    15] loss: 1.283\n",
      "Got 309 / 495 with accuracy 62.42\n",
      "[67,     5] loss: 1.203\n",
      "[67,    10] loss: 1.256\n",
      "[67,    15] loss: 1.293\n",
      "Got 316 / 495 with accuracy 63.84\n",
      "[68,     5] loss: 1.166\n",
      "[68,    10] loss: 1.232\n",
      "[68,    15] loss: 1.275\n",
      "Got 307 / 495 with accuracy 62.02\n",
      "[69,     5] loss: 1.244\n",
      "[69,    10] loss: 1.171\n",
      "[69,    15] loss: 1.154\n",
      "Got 314 / 495 with accuracy 63.43\n",
      "[70,     5] loss: 1.115\n",
      "[70,    10] loss: 1.173\n",
      "[70,    15] loss: 1.226\n",
      "Got 310 / 495 with accuracy 62.63\n",
      "[71,     5] loss: 1.229\n",
      "[71,    10] loss: 1.112\n",
      "[71,    15] loss: 1.101\n",
      "Got 311 / 495 with accuracy 62.83\n",
      "[72,     5] loss: 1.069\n",
      "[72,    10] loss: 1.073\n",
      "[72,    15] loss: 1.201\n",
      "Got 309 / 495 with accuracy 62.42\n",
      "[73,     5] loss: 1.108\n",
      "[73,    10] loss: 1.080\n",
      "[73,    15] loss: 1.067\n",
      "Got 304 / 495 with accuracy 61.41\n",
      "[74,     5] loss: 1.065\n",
      "[74,    10] loss: 1.039\n",
      "[74,    15] loss: 1.048\n",
      "Got 304 / 495 with accuracy 61.41\n",
      "[75,     5] loss: 1.050\n",
      "[75,    10] loss: 0.974\n",
      "[75,    15] loss: 1.068\n",
      "Got 314 / 495 with accuracy 63.43\n",
      "[76,     5] loss: 0.947\n",
      "[76,    10] loss: 1.014\n",
      "[76,    15] loss: 1.028\n",
      "Got 309 / 495 with accuracy 62.42\n",
      "[77,     5] loss: 0.974\n",
      "[77,    10] loss: 0.990\n",
      "[77,    15] loss: 0.964\n",
      "Got 311 / 495 with accuracy 62.83\n",
      "[78,     5] loss: 0.923\n",
      "[78,    10] loss: 1.027\n",
      "[78,    15] loss: 0.953\n",
      "Got 307 / 495 with accuracy 62.02\n",
      "[79,     5] loss: 0.896\n",
      "[79,    10] loss: 0.972\n",
      "[79,    15] loss: 0.917\n",
      "Got 310 / 495 with accuracy 62.63\n",
      "[80,     5] loss: 0.867\n",
      "[80,    10] loss: 0.967\n",
      "[80,    15] loss: 0.940\n",
      "Got 302 / 495 with accuracy 61.01\n",
      "[81,     5] loss: 0.922\n",
      "[81,    10] loss: 0.848\n",
      "[81,    15] loss: 0.884\n",
      "Got 302 / 495 with accuracy 61.01\n",
      "[82,     5] loss: 0.824\n",
      "[82,    10] loss: 0.956\n",
      "[82,    15] loss: 0.820\n",
      "Got 303 / 495 with accuracy 61.21\n",
      "[83,     5] loss: 0.834\n",
      "[83,    10] loss: 0.816\n",
      "[83,    15] loss: 0.875\n",
      "Got 303 / 495 with accuracy 61.21\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-35a573a5dcec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# print statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# print every 2000 mini-batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             print('[%d, %5d] loss: %.3f' %\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(100):  # loop over the dataset multiple times\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    #Training loop\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        depth_images = data['depth_images']\n",
    "        labels = data['labels']\n",
    "\n",
    "        depth_images = depth_images.to(device=device)\n",
    "        labels = labels.to(device=device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(depth_images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 5 == 4:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    #Test loop\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  \n",
    "    with torch.no_grad():\n",
    "  \n",
    "        \n",
    "        for data in validation_loader:\n",
    "            depth_images = data['depth_images']\n",
    "            labels = data['labels']\n",
    "\n",
    "            depth_images = depth_images.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "            \n",
    "            scores = model(depth_images)\n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct += (predictions == labels).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "            \n",
    "        print(f'Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15edbab",
   "metadata": {},
   "source": [
    "### Update old object to new class (Don't run every time):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc6c12c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_file = \"../data/treesXYZ/meta/META.csv\"\n",
    "data_dir = \"../data/treesXYZ/\"\n",
    "trees_new = utils.TreeSpeciesDataset(data_dir, metadata_file)\n",
    "\n",
    "trees_old=torch.load('trees_old.pt')\n",
    "\n",
    "trees_new.depth_images = trees_old.depth_images\n",
    "trees_new.labels = trees_old.labels.long()\n",
    "\n",
    "torch.save(trees_new, 'trees_new.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
