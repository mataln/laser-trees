{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c03c95c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import copy\n",
    "pdir = os.path.dirname(os.getcwd())\n",
    "sys.path.append(pdir)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "import utils\n",
    "from simpleview_pytorch import SimpleView\n",
    "\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "model_dir = 'models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfca2893",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmja2106\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82c49d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfa31ef",
   "metadata": {},
   "source": [
    "### Load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95ba9f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEFAG     1116\n",
      "PINNIG      581\n",
      "QUEILE      364\n",
      "PINSYL      277\n",
      "PINPIN      140\n",
      "NA            2\n",
      "JUNIPE        2\n",
      "QUERCUS       2\n",
      "DEAD          1\n",
      "Name: sp, dtype: int64\n",
      "Species:  ['DEAD', 'JUNIPE', 'NA', 'PINNIG', 'PINPIN', 'PINSYL', 'QUEFAG', 'QUEILE', 'QUERCUS']\n",
      "Labels:  tensor([8, 3, 6,  ..., 7, 3, 6])\n",
      "Total count:  2485\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'tree_points.pt'\n",
    "\n",
    "trees_data = torch.load(dataset_name)\n",
    "val_data = torch.load(dataset_name)\n",
    "print(trees_data.counts)\n",
    "print('Species: ', trees_data.species)\n",
    "print('Labels: ', trees_data.labels)\n",
    "print('Total count: ', len(trees_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "021d29a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type([1,2,3]) == list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84500bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.30 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.15<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">worthy-field-77</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mja2106/laser-trees\" target=\"_blank\">https://wandb.ai/mja2106/laser-trees</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/mja2106/laser-trees/runs/vaqkzncv\" target=\"_blank\">https://wandb.ai/mja2106/laser-trees/runs/vaqkzncv</a><br/>\n",
       "                Run data is saved locally in <code>/home/matt/Work/MRes-Project/laser-trees/notebooks/wandb/run-20210523_001501-vaqkzncv</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = {\n",
    "    \"dataset_type\":type(trees_data),\n",
    "    \"batch_size\":128,\n",
    "    \"validation_split\":.2,\n",
    "    \"shuffle_dataset\":True,\n",
    "    \"random_seed\":0,\n",
    "    \"learning_rate\":[0.0005, 100, 0.5],  #[init, step_size, gamma] for scheduler\n",
    "    \"momentum\":0.9, #Only used for sgd\n",
    "    \"epochs\":300,\n",
    "    \"loss_fn\":\"cross-entropy\",\n",
    "    \"optimizer\":\"adam\",\n",
    "    \"voting\":\"None\",\n",
    "    \n",
    "    \"model\":\"SimpleView\",\n",
    "    \n",
    "    \"image_dim\":trees_data.image_dim,\n",
    "    \"camera_fov_deg\":trees_data.camera_fov_deg,\n",
    "    \"f\":trees_data.f,\n",
    "    \"camera_dist\":trees_data.camera_dist,\n",
    "    \"depth_averaging\":\"min\",\n",
    "    \n",
    "    \"transforms\":['rotation','translation','jitter'],\n",
    "    \"min_rotation\":0,\n",
    "    \"max_rotation\":2*np.pi,\n",
    "    \"min_translation\":0,\n",
    "    \"max_translation\":0.1,\n",
    "    \"jitter_std\":3e-4, \n",
    "    \n",
    "    \"species\":[\"QUEFAG\", \"PINNIG\", \"QUEILE\", \"PINSYL\", \"PINPIN\"],\n",
    "    \"data_resolution\":\"2.5cm\"\n",
    "}\n",
    "\n",
    "\n",
    "if params[\"dataset_type\"] == utils.dataset.TreeSpeciesPointDataset: #Change these by hand using point dataset\n",
    "    params[\"image_dim\"] = 256\n",
    "    params[\"camera_fov_deg\"] = 90 \n",
    "    params[\"f\"] = 1\n",
    "    params[\"camera_dist\"] = 1.4\n",
    "    params[\"depth_averaging\"] = \"min\"\n",
    "    params[\"soft_min_k\"] = 50\n",
    "    params[\"num_views\"] = 6\n",
    "    \n",
    "    trees_data.set_params(image_dim = params[\"image_dim\"],\n",
    "                         camera_fov_deg = params[\"camera_fov_deg\"],\n",
    "                         f = params[\"f\"],\n",
    "                         camera_dist = params[\"camera_dist\"],\n",
    "                         soft_min_k = params[\"soft_min_k\"],\n",
    "                         transforms = params[\"transforms\"],\n",
    "                         min_rotation = params[\"min_rotation\"],\n",
    "                         max_rotation = params[\"max_rotation\"],\n",
    "                         min_translation = params[\"min_translation\"],\n",
    "                         max_translation = params[\"max_translation\"],\n",
    "                         jitter_std = params[\"jitter_std\"]\n",
    "                         )\n",
    "    \n",
    "    val_data.set_params(image_dim = params[\"image_dim\"],\n",
    "                         camera_fov_deg = params[\"camera_fov_deg\"],\n",
    "                         f = params[\"f\"],\n",
    "                         camera_dist = params[\"camera_dist\"],\n",
    "                         soft_min_k = params[\"soft_min_k\"],\n",
    "                         transforms = params[\"transforms\"],\n",
    "                         min_rotation = params[\"min_rotation\"],\n",
    "                         max_rotation = params[\"max_rotation\"],\n",
    "                         min_translation = params[\"min_translation\"],\n",
    "                         max_translation = params[\"max_translation\"],\n",
    "                         jitter_std = params[\"jitter_std\"]\n",
    "                         )\n",
    "    \n",
    "elif params[\"dataset_type\"] == utils.dataset.TreeSpeciesDataset:\n",
    "    params[\"image_dim\"] = trees_data.image_dim\n",
    "    params[\"camera_fov_deg\"] = trees_data.camera_fov_deg\n",
    "    params[\"f\"] = trees_data.f\n",
    "    params[\"camera_dist\"] = trees_data.camera_dist\n",
    "    params[\"num_views\"] = trees_data.depth_images.shape[1]\n",
    "    params[\"depth_averaging\"] = \"min\"\n",
    "\n",
    "    \n",
    "if trees_data.soft_min_k:\n",
    "    params[\"soft_min_k\"] = trees_data.soft_min_k\n",
    "\n",
    "experiment_name = wandb.util.generate_id()\n",
    "    \n",
    "run = wandb.init(\n",
    "    project='laser-trees',\n",
    "    group=experiment_name,\n",
    "    config=params)    \n",
    "\n",
    "config = wandb.config\n",
    "torch.manual_seed(config.random_seed)\n",
    "torch.cuda.manual_seed(config.random_seed)\n",
    "np.random.seed(config.random_seed)\n",
    "random.seed(config.random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56ae4f5",
   "metadata": {},
   "source": [
    "#### Remove low-count species:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38890049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing: QUERCUS\n",
      "Removing: JUNIPE\n",
      "Removing: NA\n",
      "Removing: DEAD\n",
      "Train Dataset:\n",
      "QUEFAG    1116\n",
      "PINNIG     581\n",
      "QUEILE     364\n",
      "PINSYL     277\n",
      "PINPIN     140\n",
      "Name: sp, dtype: int64\n",
      "Species:  ['PINNIG', 'PINPIN', 'PINSYL', 'QUEFAG', 'QUEILE']\n",
      "Labels:  tensor([0, 3, 3,  ..., 4, 0, 3])\n",
      "Total count:  2478\n",
      "\n",
      "Validation Dataset (should match):\n",
      "QUEFAG    1116\n",
      "PINNIG     581\n",
      "QUEILE     364\n",
      "PINSYL     277\n",
      "PINPIN     140\n",
      "Name: sp, dtype: int64\n",
      "Species:  ['PINNIG', 'PINPIN', 'PINSYL', 'QUEFAG', 'QUEILE']\n",
      "Labels:  tensor([0, 3, 3,  ..., 4, 0, 3])\n",
      "Total count:  2478\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for specie in list(set(trees_data.species) - set(config.species)):\n",
    "    print(\"Removing: {}\".format(specie))\n",
    "    trees_data.remove_species(specie)\n",
    "    val_data.remove_species(specie)\n",
    "\n",
    "print('Train Dataset:')\n",
    "print(trees_data.counts)\n",
    "print('Species: ', trees_data.species)\n",
    "print('Labels: ', trees_data.labels)\n",
    "print('Total count: ', len(trees_data))\n",
    "print()\n",
    "\n",
    "print('Validation Dataset (should match):')\n",
    "print(val_data.counts)\n",
    "print('Species: ', val_data.species)\n",
    "print('Labels: ', val_data.labels)\n",
    "print('Total count: ', len(val_data))\n",
    "print()\n",
    "\n",
    "assert len(val_data) == len(trees_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3907ca",
   "metadata": {},
   "source": [
    "#### Train-validation split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e67fa570",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(trees_data)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(config.validation_split * dataset_size))\n",
    "\n",
    "if config.shuffle_dataset :\n",
    "    \n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f378d0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trees_data, batch_size=config.batch_size, \n",
    "                                           sampler=train_sampler)\n",
    "\n",
    "val_data.set_params(transforms=['none']) #Turn off transforms for the validation dataset - DON'T GIVE IT AN EMPTY LIST\n",
    "validation_loader = torch.utils.data.DataLoader(trees_data, batch_size=config.batch_size,\n",
    "                                                sampler=valid_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e57320a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run to print no. instances of each class\n",
    "if None:\n",
    "    for x in train_loader:\n",
    "        print(torch.unique(x['labels'], return_counts = True))\n",
    "    print()\n",
    "\n",
    "    for x in validation_loader:\n",
    "        print(torch.unique(x['labels'], return_counts = True))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b735cf",
   "metadata": {},
   "source": [
    "### Define model, loss fn, optimiser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e22ec264",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(config.species) == set(trees_data.species)\n",
    "\n",
    "if config.model==\"SimpleView\":\n",
    "    model = SimpleView(\n",
    "        num_views=config.num_views,\n",
    "        num_classes=len(config.species)\n",
    "    )\n",
    "\n",
    "model = model.to(device=device)\n",
    "\n",
    "if config.loss_fn==\"cross-entropy\":\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "if config.loss_fn==\"smooth-loss\":\n",
    "    loss_fn = utils.smooth_loss\n",
    "\n",
    "if type(config.learning_rate) == list:\n",
    "    lr = config.learning_rate[0]\n",
    "    step_size = config.learning_rate[1]\n",
    "    gamma = config.learning_rate[2]\n",
    "else:\n",
    "    lr = config.learning_rate\n",
    "    \n",
    "if config.optimizer==\"sgd\":\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=config.momentum)\n",
    "elif config.optimizer==\"adam\":\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "if type(config.learning_rate) == list:\n",
    "    scheduler = StepLR(optimizer, step_size=step_size, gamma=gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4722b35d",
   "metadata": {},
   "source": [
    "### Train & Test Loops:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1479fbc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matt/Work/MRes-Project/laser-trees/utils/utils.py:127: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_world_tilde=torch.cat((torch.tensor(cloud), torch.ones(cloud.shape[0],1)), 1).transpose(0,1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     5] loss: 3.390\n",
      "[1,    10] loss: 3.039\n",
      "[1,    15] loss: 2.853\n",
      "Got 89 / 495 with accuracy 17.98\n",
      "[2,     5] loss: 2.794\n",
      "[2,    10] loss: 2.589\n",
      "[2,    15] loss: 2.497\n",
      "Got 53 / 495 with accuracy 10.71\n",
      "[3,     5] loss: 2.382\n",
      "[3,    10] loss: 2.344\n",
      "[3,    15] loss: 2.521\n",
      "Got 212 / 495 with accuracy 42.83\n",
      "[4,     5] loss: 2.259\n",
      "[4,    10] loss: 2.294\n",
      "[4,    15] loss: 2.166\n",
      "Got 252 / 495 with accuracy 50.91\n",
      "[5,     5] loss: 2.236\n",
      "[5,    10] loss: 2.149\n",
      "[5,    15] loss: 2.170\n",
      "Got 154 / 495 with accuracy 31.11\n",
      "[6,     5] loss: 2.137\n",
      "[6,    10] loss: 2.260\n",
      "[6,    15] loss: 1.975\n",
      "Got 332 / 495 with accuracy 67.07\n",
      "[7,     5] loss: 2.059\n",
      "[7,    10] loss: 1.999\n",
      "[7,    15] loss: 2.144\n",
      "Got 328 / 495 with accuracy 66.26\n",
      "[8,     5] loss: 1.990\n",
      "[8,    10] loss: 2.046\n",
      "[8,    15] loss: 2.095\n",
      "Got 345 / 495 with accuracy 69.70\n",
      "[9,     5] loss: 2.040\n",
      "[9,    10] loss: 2.183\n",
      "[9,    15] loss: 1.901\n",
      "Got 280 / 495 with accuracy 56.57\n",
      "[10,     5] loss: 2.063\n",
      "[10,    10] loss: 1.926\n",
      "[10,    15] loss: 1.909\n",
      "Got 285 / 495 with accuracy 57.58\n",
      "[11,     5] loss: 1.959\n",
      "[11,    10] loss: 1.959\n",
      "[11,    15] loss: 2.017\n",
      "Got 272 / 495 with accuracy 54.95\n",
      "[12,     5] loss: 2.015\n",
      "[12,    10] loss: 1.955\n",
      "[12,    15] loss: 1.823\n",
      "Got 158 / 495 with accuracy 31.92\n",
      "[13,     5] loss: 1.808\n",
      "[13,    10] loss: 1.896\n",
      "[13,    15] loss: 1.935\n",
      "Got 346 / 495 with accuracy 69.90\n",
      "[14,     5] loss: 1.805\n",
      "[14,    10] loss: 1.969\n",
      "[14,    15] loss: 1.952\n",
      "Got 317 / 495 with accuracy 64.04\n",
      "[15,     5] loss: 1.863\n",
      "[15,    10] loss: 1.863\n",
      "[15,    15] loss: 1.932\n",
      "Got 354 / 495 with accuracy 71.52\n",
      "[16,     5] loss: 1.757\n",
      "[16,    10] loss: 1.989\n",
      "[16,    15] loss: 1.866\n",
      "Got 275 / 495 with accuracy 55.56\n",
      "[17,     5] loss: 1.813\n",
      "[17,    10] loss: 1.958\n",
      "[17,    15] loss: 1.823\n",
      "Got 334 / 495 with accuracy 67.47\n",
      "[18,     5] loss: 1.885\n",
      "[18,    10] loss: 1.712\n",
      "[18,    15] loss: 1.905\n",
      "Got 230 / 495 with accuracy 46.46\n",
      "[19,     5] loss: 1.781\n",
      "[19,    10] loss: 1.880\n",
      "[19,    15] loss: 1.821\n",
      "Got 265 / 495 with accuracy 53.54\n",
      "[20,     5] loss: 1.843\n",
      "[20,    10] loss: 1.825\n",
      "[20,    15] loss: 1.637\n",
      "Got 334 / 495 with accuracy 67.47\n",
      "[21,     5] loss: 1.709\n",
      "[21,    10] loss: 1.796\n",
      "[21,    15] loss: 1.703\n",
      "Got 338 / 495 with accuracy 68.28\n",
      "[22,     5] loss: 1.709\n",
      "[22,    10] loss: 1.730\n",
      "[22,    15] loss: 1.612\n",
      "Got 360 / 495 with accuracy 72.73\n",
      "[23,     5] loss: 1.658\n",
      "[23,    10] loss: 1.794\n",
      "[23,    15] loss: 1.640\n",
      "Got 285 / 495 with accuracy 57.58\n",
      "[24,     5] loss: 1.615\n",
      "[24,    10] loss: 1.655\n",
      "[24,    15] loss: 1.641\n",
      "Got 311 / 495 with accuracy 62.83\n",
      "[25,     5] loss: 1.649\n",
      "[25,    10] loss: 1.662\n",
      "[25,    15] loss: 1.601\n",
      "Got 267 / 495 with accuracy 53.94\n",
      "[26,     5] loss: 1.653\n",
      "[26,    10] loss: 1.702\n",
      "[26,    15] loss: 1.670\n",
      "Got 282 / 495 with accuracy 56.97\n",
      "[27,     5] loss: 1.532\n",
      "[27,    10] loss: 1.525\n",
      "[27,    15] loss: 1.707\n",
      "Got 332 / 495 with accuracy 67.07\n",
      "[28,     5] loss: 1.467\n",
      "[28,    10] loss: 1.534\n",
      "[28,    15] loss: 1.646\n",
      "Got 322 / 495 with accuracy 65.05\n",
      "[29,     5] loss: 1.648\n",
      "[29,    10] loss: 1.368\n",
      "[29,    15] loss: 1.584\n",
      "Got 255 / 495 with accuracy 51.52\n",
      "[30,     5] loss: 1.656\n",
      "[30,    10] loss: 1.546\n",
      "[30,    15] loss: 1.501\n",
      "Got 305 / 495 with accuracy 61.62\n",
      "[31,     5] loss: 1.480\n",
      "[31,    10] loss: 1.551\n",
      "[31,    15] loss: 1.465\n",
      "Got 189 / 495 with accuracy 38.18\n",
      "[32,     5] loss: 1.527\n",
      "[32,    10] loss: 1.366\n",
      "[32,    15] loss: 1.504\n",
      "Got 361 / 495 with accuracy 72.93\n",
      "[33,     5] loss: 1.474\n",
      "[33,    10] loss: 1.377\n",
      "[33,    15] loss: 1.521\n",
      "Got 294 / 495 with accuracy 59.39\n",
      "[34,     5] loss: 1.409\n",
      "[34,    10] loss: 1.450\n",
      "[34,    15] loss: 1.518\n",
      "Got 239 / 495 with accuracy 48.28\n",
      "[35,     5] loss: 1.475\n",
      "[35,    10] loss: 1.456\n",
      "[35,    15] loss: 1.443\n",
      "Got 275 / 495 with accuracy 55.56\n",
      "[36,     5] loss: 1.463\n",
      "[36,    10] loss: 1.495\n",
      "[36,    15] loss: 1.394\n",
      "Got 310 / 495 with accuracy 62.63\n",
      "[37,     5] loss: 1.294\n",
      "[37,    10] loss: 1.405\n",
      "[37,    15] loss: 1.532\n",
      "Got 290 / 495 with accuracy 58.59\n",
      "[38,     5] loss: 1.342\n",
      "[38,    10] loss: 1.429\n",
      "[38,    15] loss: 1.279\n",
      "Got 381 / 495 with accuracy 76.97\n",
      "[39,     5] loss: 1.208\n",
      "[39,    10] loss: 1.451\n",
      "[39,    15] loss: 1.355\n",
      "Got 244 / 495 with accuracy 49.29\n",
      "[40,     5] loss: 1.350\n",
      "[40,    10] loss: 1.266\n",
      "[40,    15] loss: 1.406\n",
      "Got 343 / 495 with accuracy 69.29\n",
      "[41,     5] loss: 1.255\n",
      "[41,    10] loss: 1.339\n",
      "[41,    15] loss: 1.337\n",
      "Got 361 / 495 with accuracy 72.93\n",
      "[42,     5] loss: 1.307\n",
      "[42,    10] loss: 1.273\n",
      "[42,    15] loss: 1.227\n",
      "Got 368 / 495 with accuracy 74.34\n",
      "[43,     5] loss: 1.369\n",
      "[43,    10] loss: 1.302\n",
      "[43,    15] loss: 1.360\n",
      "Got 324 / 495 with accuracy 65.45\n",
      "[44,     5] loss: 1.290\n",
      "[44,    10] loss: 1.183\n",
      "[44,    15] loss: 1.258\n",
      "Got 369 / 495 with accuracy 74.55\n",
      "[45,     5] loss: 1.377\n",
      "[45,    10] loss: 1.435\n",
      "[45,    15] loss: 1.385\n",
      "Got 332 / 495 with accuracy 67.07\n",
      "[46,     5] loss: 1.154\n",
      "[46,    10] loss: 1.304\n",
      "[46,    15] loss: 1.398\n",
      "Got 332 / 495 with accuracy 67.07\n",
      "[47,     5] loss: 1.275\n",
      "[47,    10] loss: 1.227\n",
      "[47,    15] loss: 1.123\n",
      "Got 369 / 495 with accuracy 74.55\n",
      "[48,     5] loss: 1.298\n",
      "[48,    10] loss: 1.294\n",
      "[48,    15] loss: 1.118\n",
      "Got 360 / 495 with accuracy 72.73\n",
      "[49,     5] loss: 1.154\n",
      "[49,    10] loss: 1.183\n",
      "[49,    15] loss: 1.176\n",
      "Got 221 / 495 with accuracy 44.65\n",
      "[50,     5] loss: 1.183\n",
      "[50,    10] loss: 1.089\n",
      "[50,    15] loss: 1.218\n",
      "Got 354 / 495 with accuracy 71.52\n",
      "[51,     5] loss: 1.126\n",
      "[51,    10] loss: 1.204\n",
      "[51,    15] loss: 1.196\n",
      "Got 329 / 495 with accuracy 66.46\n",
      "[52,     5] loss: 1.130\n",
      "[52,    10] loss: 1.153\n",
      "[52,    15] loss: 1.116\n",
      "Got 361 / 495 with accuracy 72.93\n",
      "[53,     5] loss: 1.248\n",
      "[53,    10] loss: 1.118\n",
      "[53,    15] loss: 1.086\n",
      "Got 353 / 495 with accuracy 71.31\n",
      "[54,     5] loss: 1.070\n",
      "[54,    10] loss: 1.043\n",
      "[54,    15] loss: 1.242\n",
      "Got 269 / 495 with accuracy 54.34\n",
      "[55,     5] loss: 1.025\n",
      "[55,    10] loss: 1.110\n",
      "[55,    15] loss: 1.259\n",
      "Got 299 / 495 with accuracy 60.40\n",
      "[56,     5] loss: 0.985\n",
      "[56,    10] loss: 1.030\n",
      "[56,    15] loss: 1.132\n",
      "Got 372 / 495 with accuracy 75.15\n",
      "[57,     5] loss: 0.993\n",
      "[57,    10] loss: 1.055\n",
      "[57,    15] loss: 1.099\n",
      "Got 289 / 495 with accuracy 58.38\n",
      "[58,     5] loss: 1.086\n",
      "[58,    10] loss: 1.058\n",
      "[58,    15] loss: 1.086\n",
      "Got 337 / 495 with accuracy 68.08\n",
      "[59,     5] loss: 1.062\n",
      "[59,    10] loss: 1.141\n",
      "[59,    15] loss: 1.040\n",
      "Got 297 / 495 with accuracy 60.00\n",
      "[60,     5] loss: 1.065\n",
      "[60,    10] loss: 1.025\n",
      "[60,    15] loss: 1.003\n",
      "Got 330 / 495 with accuracy 66.67\n",
      "[61,     5] loss: 0.981\n",
      "[61,    10] loss: 1.051\n",
      "[61,    15] loss: 0.968\n",
      "Got 311 / 495 with accuracy 62.83\n",
      "[62,     5] loss: 1.007\n",
      "[62,    10] loss: 0.945\n",
      "[62,    15] loss: 1.098\n",
      "Got 369 / 495 with accuracy 74.55\n",
      "[63,     5] loss: 1.017\n",
      "[63,    10] loss: 1.102\n",
      "[63,    15] loss: 0.972\n",
      "Got 378 / 495 with accuracy 76.36\n",
      "[64,     5] loss: 1.199\n",
      "[64,    10] loss: 1.039\n",
      "[64,    15] loss: 0.955\n",
      "Got 186 / 495 with accuracy 37.58\n",
      "[65,     5] loss: 1.007\n",
      "[65,    10] loss: 1.000\n",
      "[65,    15] loss: 0.985\n",
      "Got 340 / 495 with accuracy 68.69\n",
      "[66,     5] loss: 0.917\n",
      "[66,    10] loss: 0.920\n",
      "[66,    15] loss: 0.947\n",
      "Got 315 / 495 with accuracy 63.64\n",
      "[67,     5] loss: 0.870\n",
      "[67,    10] loss: 0.818\n",
      "[67,    15] loss: 0.967\n",
      "Got 203 / 495 with accuracy 41.01\n",
      "[68,     5] loss: 1.036\n",
      "[68,    10] loss: 0.940\n",
      "[68,    15] loss: 0.934\n",
      "Got 338 / 495 with accuracy 68.28\n",
      "[69,     5] loss: 0.860\n",
      "[69,    10] loss: 0.820\n",
      "[69,    15] loss: 0.970\n",
      "Got 356 / 495 with accuracy 71.92\n",
      "[70,     5] loss: 0.894\n",
      "[70,    10] loss: 0.916\n",
      "[70,    15] loss: 0.948\n",
      "Got 315 / 495 with accuracy 63.64\n",
      "[71,     5] loss: 0.908\n",
      "[71,    10] loss: 0.899\n",
      "[71,    15] loss: 0.977\n",
      "Got 352 / 495 with accuracy 71.11\n",
      "[72,     5] loss: 0.836\n",
      "[72,    10] loss: 0.869\n",
      "[72,    15] loss: 0.862\n",
      "Got 268 / 495 with accuracy 54.14\n",
      "[73,     5] loss: 0.862\n",
      "[73,    10] loss: 0.910\n",
      "[73,    15] loss: 0.797\n",
      "Got 346 / 495 with accuracy 69.90\n",
      "[74,     5] loss: 0.846\n",
      "[74,    10] loss: 0.956\n",
      "[74,    15] loss: 0.754\n",
      "Got 343 / 495 with accuracy 69.29\n",
      "[75,     5] loss: 0.872\n",
      "[75,    10] loss: 0.867\n",
      "[75,    15] loss: 0.880\n",
      "Got 315 / 495 with accuracy 63.64\n",
      "[76,     5] loss: 0.736\n",
      "[76,    10] loss: 0.807\n",
      "[76,    15] loss: 0.844\n",
      "Got 329 / 495 with accuracy 66.46\n",
      "[77,     5] loss: 0.830\n",
      "[77,    10] loss: 0.891\n",
      "[77,    15] loss: 0.843\n",
      "Got 382 / 495 with accuracy 77.17\n",
      "[78,     5] loss: 0.771\n",
      "[78,    10] loss: 0.879\n",
      "[78,    15] loss: 0.902\n",
      "Got 350 / 495 with accuracy 70.71\n",
      "[79,     5] loss: 0.655\n",
      "[79,    10] loss: 0.686\n",
      "[79,    15] loss: 0.779\n",
      "Got 363 / 495 with accuracy 73.33\n",
      "[80,     5] loss: 0.787\n",
      "[80,    10] loss: 0.695\n",
      "[80,    15] loss: 0.745\n",
      "Got 341 / 495 with accuracy 68.89\n",
      "[81,     5] loss: 0.825\n",
      "[81,    10] loss: 0.664\n",
      "[81,    15] loss: 0.760\n",
      "Got 283 / 495 with accuracy 57.17\n",
      "[82,     5] loss: 0.792\n",
      "[82,    10] loss: 0.778\n",
      "[82,    15] loss: 0.737\n",
      "Got 378 / 495 with accuracy 76.36\n",
      "[83,     5] loss: 0.637\n",
      "[83,    10] loss: 0.911\n",
      "[83,    15] loss: 0.725\n",
      "Got 322 / 495 with accuracy 65.05\n",
      "[84,     5] loss: 0.724\n",
      "[84,    10] loss: 0.738\n",
      "[84,    15] loss: 0.766\n",
      "Got 334 / 495 with accuracy 67.47\n",
      "[85,     5] loss: 0.702\n",
      "[85,    10] loss: 0.677\n",
      "[85,    15] loss: 0.717\n",
      "Got 354 / 495 with accuracy 71.52\n",
      "[86,     5] loss: 0.906\n",
      "[86,    10] loss: 0.670\n",
      "[86,    15] loss: 0.648\n",
      "Got 362 / 495 with accuracy 73.13\n",
      "[87,     5] loss: 0.738\n",
      "[87,    10] loss: 0.759\n",
      "[87,    15] loss: 0.654\n",
      "Got 345 / 495 with accuracy 69.70\n",
      "[88,     5] loss: 0.716\n",
      "[88,    10] loss: 0.660\n",
      "[88,    15] loss: 0.738\n",
      "Got 367 / 495 with accuracy 74.14\n",
      "[89,     5] loss: 0.630\n",
      "[89,    10] loss: 0.670\n",
      "[89,    15] loss: 0.646\n",
      "Got 193 / 495 with accuracy 38.99\n",
      "[90,     5] loss: 0.635\n",
      "[90,    10] loss: 0.622\n",
      "[90,    15] loss: 0.728\n",
      "Got 175 / 495 with accuracy 35.35\n",
      "[91,     5] loss: 0.554\n",
      "[91,    10] loss: 0.532\n",
      "[91,    15] loss: 0.636\n",
      "Got 349 / 495 with accuracy 70.51\n",
      "[92,     5] loss: 0.553\n",
      "[92,    10] loss: 0.606\n",
      "[92,    15] loss: 0.673\n",
      "Got 338 / 495 with accuracy 68.28\n",
      "[93,     5] loss: 0.630\n",
      "[93,    10] loss: 0.562\n",
      "[93,    15] loss: 0.597\n",
      "Got 305 / 495 with accuracy 61.62\n",
      "[94,     5] loss: 0.438\n",
      "[94,    10] loss: 0.722\n",
      "[94,    15] loss: 0.581\n",
      "Got 319 / 495 with accuracy 64.44\n",
      "[95,     5] loss: 0.569\n",
      "[95,    10] loss: 0.657\n",
      "[95,    15] loss: 0.599\n",
      "Got 338 / 495 with accuracy 68.28\n",
      "[96,     5] loss: 0.582\n",
      "[96,    10] loss: 0.600\n",
      "[96,    15] loss: 0.694\n",
      "Got 253 / 495 with accuracy 51.11\n",
      "[97,     5] loss: 0.571\n",
      "[97,    10] loss: 0.762\n",
      "[97,    15] loss: 0.596\n",
      "Got 286 / 495 with accuracy 57.78\n",
      "[98,     5] loss: 0.715\n",
      "[98,    10] loss: 0.635\n",
      "[98,    15] loss: 0.691\n",
      "Got 273 / 495 with accuracy 55.15\n",
      "[99,     5] loss: 0.524\n",
      "[99,    10] loss: 0.621\n",
      "[99,    15] loss: 0.569\n",
      "Got 357 / 495 with accuracy 72.12\n",
      "[100,     5] loss: 0.592\n",
      "[100,    10] loss: 0.573\n",
      "[100,    15] loss: 0.575\n",
      "Got 309 / 495 with accuracy 62.42\n",
      "[101,     5] loss: 0.490\n",
      "[101,    10] loss: 0.473\n",
      "[101,    15] loss: 0.422\n",
      "Got 343 / 495 with accuracy 69.29\n",
      "[102,     5] loss: 0.422\n",
      "[102,    10] loss: 0.449\n",
      "[102,    15] loss: 0.431\n",
      "Got 379 / 495 with accuracy 76.57\n",
      "[103,     5] loss: 0.430\n",
      "[103,    10] loss: 0.363\n",
      "[103,    15] loss: 0.439\n",
      "Got 366 / 495 with accuracy 73.94\n",
      "[104,     5] loss: 0.412\n",
      "[104,    10] loss: 0.394\n",
      "[104,    15] loss: 0.390\n",
      "Got 382 / 495 with accuracy 77.17\n",
      "[105,     5] loss: 0.441\n",
      "[105,    10] loss: 0.477\n",
      "[105,    15] loss: 0.370\n",
      "Got 337 / 495 with accuracy 68.08\n",
      "[106,     5] loss: 0.346\n",
      "[106,    10] loss: 0.469\n",
      "[106,    15] loss: 0.501\n",
      "Got 303 / 495 with accuracy 61.21\n",
      "[107,     5] loss: 0.318\n",
      "[107,    10] loss: 0.400\n",
      "[107,    15] loss: 0.445\n",
      "Got 389 / 495 with accuracy 78.59\n",
      "[108,     5] loss: 0.423\n",
      "[108,    10] loss: 0.392\n",
      "[108,    15] loss: 0.378\n",
      "Got 353 / 495 with accuracy 71.31\n",
      "[109,     5] loss: 0.333\n",
      "[109,    10] loss: 0.368\n",
      "[109,    15] loss: 0.345\n",
      "Got 385 / 495 with accuracy 77.78\n",
      "[110,     5] loss: 0.345\n",
      "[110,    10] loss: 0.384\n",
      "[110,    15] loss: 0.351\n",
      "Got 201 / 495 with accuracy 40.61\n",
      "[111,     5] loss: 0.341\n",
      "[111,    10] loss: 0.383\n",
      "[111,    15] loss: 0.373\n",
      "Got 379 / 495 with accuracy 76.57\n",
      "[112,     5] loss: 0.296\n",
      "[112,    10] loss: 0.301\n",
      "[112,    15] loss: 0.412\n",
      "Got 383 / 495 with accuracy 77.37\n",
      "[113,     5] loss: 0.367\n",
      "[113,    10] loss: 0.378\n",
      "[113,    15] loss: 0.318\n",
      "Got 379 / 495 with accuracy 76.57\n",
      "[114,     5] loss: 0.289\n",
      "[114,    10] loss: 0.412\n",
      "[114,    15] loss: 0.335\n",
      "Got 373 / 495 with accuracy 75.35\n",
      "[115,     5] loss: 0.337\n",
      "[115,    10] loss: 0.360\n",
      "[115,    15] loss: 0.419\n",
      "Got 352 / 495 with accuracy 71.11\n",
      "[116,     5] loss: 0.338\n",
      "[116,    10] loss: 0.326\n",
      "[116,    15] loss: 0.359\n",
      "Got 379 / 495 with accuracy 76.57\n",
      "[117,     5] loss: 0.259\n",
      "[117,    10] loss: 0.246\n",
      "[117,    15] loss: 0.315\n",
      "Got 338 / 495 with accuracy 68.28\n",
      "[118,     5] loss: 0.285\n",
      "[118,    10] loss: 0.367\n",
      "[118,    15] loss: 0.290\n",
      "Got 377 / 495 with accuracy 76.16\n",
      "[119,     5] loss: 0.328\n",
      "[119,    10] loss: 0.279\n",
      "[119,    15] loss: 0.387\n",
      "Got 359 / 495 with accuracy 72.53\n",
      "[120,     5] loss: 0.310\n",
      "[120,    10] loss: 0.336\n",
      "[120,    15] loss: 0.392\n",
      "Got 349 / 495 with accuracy 70.51\n",
      "[121,     5] loss: 0.287\n",
      "[121,    10] loss: 0.365\n",
      "[121,    15] loss: 0.340\n",
      "Got 360 / 495 with accuracy 72.73\n",
      "[122,     5] loss: 0.260\n",
      "[122,    10] loss: 0.312\n",
      "[122,    15] loss: 0.286\n",
      "Got 395 / 495 with accuracy 79.80\n",
      "[123,     5] loss: 0.310\n",
      "[123,    10] loss: 0.247\n",
      "[123,    15] loss: 0.308\n",
      "Got 328 / 495 with accuracy 66.26\n",
      "[124,     5] loss: 0.254\n",
      "[124,    10] loss: 0.289\n",
      "[124,    15] loss: 0.318\n",
      "Got 385 / 495 with accuracy 77.78\n",
      "[125,     5] loss: 0.272\n",
      "[125,    10] loss: 0.343\n",
      "[125,    15] loss: 0.272\n",
      "Got 376 / 495 with accuracy 75.96\n",
      "[126,     5] loss: 0.277\n",
      "[126,    10] loss: 0.314\n",
      "[126,    15] loss: 0.299\n",
      "Got 361 / 495 with accuracy 72.93\n",
      "[127,     5] loss: 0.335\n",
      "[127,    10] loss: 0.285\n",
      "[127,    15] loss: 0.344\n",
      "Got 347 / 495 with accuracy 70.10\n",
      "[128,     5] loss: 0.307\n",
      "[128,    10] loss: 0.263\n",
      "[128,    15] loss: 0.328\n",
      "Got 364 / 495 with accuracy 73.54\n",
      "[129,     5] loss: 0.293\n",
      "[129,    10] loss: 0.268\n",
      "[129,    15] loss: 0.257\n",
      "Got 360 / 495 with accuracy 72.73\n",
      "[130,     5] loss: 0.272\n",
      "[130,    10] loss: 0.262\n",
      "[130,    15] loss: 0.246\n",
      "Got 391 / 495 with accuracy 78.99\n",
      "[131,     5] loss: 0.242\n",
      "[131,    10] loss: 0.204\n",
      "[131,    15] loss: 0.264\n",
      "Got 384 / 495 with accuracy 77.58\n",
      "[132,     5] loss: 0.234\n",
      "[132,    10] loss: 0.304\n",
      "[132,    15] loss: 0.239\n",
      "Got 378 / 495 with accuracy 76.36\n",
      "[133,     5] loss: 0.246\n",
      "[133,    10] loss: 0.203\n",
      "[133,    15] loss: 0.279\n",
      "Got 385 / 495 with accuracy 77.78\n",
      "[134,     5] loss: 0.273\n",
      "[134,    10] loss: 0.256\n",
      "[134,    15] loss: 0.248\n",
      "Got 335 / 495 with accuracy 67.68\n",
      "[135,     5] loss: 0.285\n",
      "[135,    10] loss: 0.324\n",
      "[135,    15] loss: 0.308\n",
      "Got 345 / 495 with accuracy 69.70\n",
      "[136,     5] loss: 0.353\n",
      "[136,    10] loss: 0.250\n",
      "[136,    15] loss: 0.331\n",
      "Got 343 / 495 with accuracy 69.29\n",
      "[137,     5] loss: 0.271\n",
      "[137,    10] loss: 0.304\n",
      "[137,    15] loss: 0.267\n",
      "Got 306 / 495 with accuracy 61.82\n",
      "[138,     5] loss: 0.277\n",
      "[138,    10] loss: 0.235\n",
      "[138,    15] loss: 0.271\n",
      "Got 391 / 495 with accuracy 78.99\n",
      "[139,     5] loss: 0.261\n",
      "[139,    10] loss: 0.222\n",
      "[139,    15] loss: 0.232\n",
      "Got 382 / 495 with accuracy 77.17\n",
      "[140,     5] loss: 0.216\n",
      "[140,    10] loss: 0.213\n",
      "[140,    15] loss: 0.225\n",
      "Got 316 / 495 with accuracy 63.84\n",
      "[141,     5] loss: 0.254\n",
      "[141,    10] loss: 0.230\n",
      "[141,    15] loss: 0.327\n",
      "Got 312 / 495 with accuracy 63.03\n",
      "[142,     5] loss: 0.282\n",
      "[142,    10] loss: 0.240\n",
      "[142,    15] loss: 0.256\n",
      "Got 374 / 495 with accuracy 75.56\n",
      "[143,     5] loss: 0.231\n",
      "[143,    10] loss: 0.286\n",
      "[143,    15] loss: 0.255\n",
      "Got 358 / 495 with accuracy 72.32\n",
      "[144,     5] loss: 0.223\n",
      "[144,    10] loss: 0.249\n",
      "[144,    15] loss: 0.250\n",
      "Got 350 / 495 with accuracy 70.71\n",
      "[145,     5] loss: 0.281\n",
      "[145,    10] loss: 0.210\n",
      "[145,    15] loss: 0.281\n",
      "Got 377 / 495 with accuracy 76.16\n",
      "[146,     5] loss: 0.271\n",
      "[146,    10] loss: 0.195\n",
      "[146,    15] loss: 0.218\n",
      "Got 385 / 495 with accuracy 77.78\n",
      "[147,     5] loss: 0.180\n",
      "[147,    10] loss: 0.286\n",
      "[147,    15] loss: 0.247\n",
      "Got 356 / 495 with accuracy 71.92\n",
      "[148,     5] loss: 0.172\n",
      "[148,    10] loss: 0.217\n",
      "[148,    15] loss: 0.203\n",
      "Got 402 / 495 with accuracy 81.21\n",
      "[149,     5] loss: 0.186\n",
      "[149,    10] loss: 0.179\n",
      "[149,    15] loss: 0.144\n",
      "Got 367 / 495 with accuracy 74.14\n",
      "[150,     5] loss: 0.202\n",
      "[150,    10] loss: 0.174\n",
      "[150,    15] loss: 0.236\n",
      "Got 349 / 495 with accuracy 70.51\n",
      "[151,     5] loss: 0.214\n",
      "[151,    10] loss: 0.229\n",
      "[151,    15] loss: 0.233\n",
      "Got 373 / 495 with accuracy 75.35\n",
      "[152,     5] loss: 0.215\n",
      "[152,    10] loss: 0.227\n",
      "[152,    15] loss: 0.228\n",
      "Got 322 / 495 with accuracy 65.05\n",
      "[153,     5] loss: 0.253\n",
      "[153,    10] loss: 0.222\n",
      "[153,    15] loss: 0.200\n",
      "Got 355 / 495 with accuracy 71.72\n",
      "[154,     5] loss: 0.140\n",
      "[154,    10] loss: 0.199\n",
      "[154,    15] loss: 0.193\n",
      "Got 370 / 495 with accuracy 74.75\n",
      "[155,     5] loss: 0.164\n",
      "[155,    10] loss: 0.180\n",
      "[155,    15] loss: 0.201\n",
      "Got 398 / 495 with accuracy 80.40\n",
      "[156,     5] loss: 0.202\n",
      "[156,    10] loss: 0.186\n",
      "[156,    15] loss: 0.199\n",
      "Got 382 / 495 with accuracy 77.17\n",
      "[157,     5] loss: 0.209\n",
      "[157,    10] loss: 0.202\n",
      "[157,    15] loss: 0.198\n",
      "Got 390 / 495 with accuracy 78.79\n",
      "[158,     5] loss: 0.200\n",
      "[158,    10] loss: 0.249\n",
      "[158,    15] loss: 0.177\n",
      "Got 313 / 495 with accuracy 63.23\n",
      "[159,     5] loss: 0.191\n",
      "[159,    10] loss: 0.187\n",
      "[159,    15] loss: 0.149\n",
      "Got 373 / 495 with accuracy 75.35\n",
      "[160,     5] loss: 0.133\n",
      "[160,    10] loss: 0.205\n",
      "[160,    15] loss: 0.169\n",
      "Got 381 / 495 with accuracy 76.97\n",
      "[161,     5] loss: 0.177\n",
      "[161,    10] loss: 0.134\n",
      "[161,    15] loss: 0.213\n",
      "Got 372 / 495 with accuracy 75.15\n",
      "[162,     5] loss: 0.112\n",
      "[162,    10] loss: 0.164\n",
      "[162,    15] loss: 0.131\n",
      "Got 375 / 495 with accuracy 75.76\n",
      "[163,     5] loss: 0.215\n",
      "[163,    10] loss: 0.180\n",
      "[163,    15] loss: 0.197\n",
      "Got 370 / 495 with accuracy 74.75\n",
      "[164,     5] loss: 0.149\n",
      "[164,    10] loss: 0.279\n",
      "[164,    15] loss: 0.198\n",
      "Got 376 / 495 with accuracy 75.96\n",
      "[165,     5] loss: 0.163\n",
      "[165,    10] loss: 0.189\n",
      "[165,    15] loss: 0.229\n",
      "Got 368 / 495 with accuracy 74.34\n",
      "[166,     5] loss: 0.160\n",
      "[166,    10] loss: 0.181\n",
      "[166,    15] loss: 0.195\n",
      "Got 377 / 495 with accuracy 76.16\n",
      "[167,     5] loss: 0.190\n",
      "[167,    10] loss: 0.148\n",
      "[167,    15] loss: 0.300\n",
      "Got 365 / 495 with accuracy 73.74\n",
      "[168,     5] loss: 0.227\n",
      "[168,    10] loss: 0.180\n",
      "[168,    15] loss: 0.201\n",
      "Got 368 / 495 with accuracy 74.34\n",
      "[169,     5] loss: 0.227\n",
      "[169,    10] loss: 0.214\n",
      "[169,    15] loss: 0.199\n",
      "Got 375 / 495 with accuracy 75.76\n",
      "[170,     5] loss: 0.181\n",
      "[170,    10] loss: 0.211\n",
      "[170,    15] loss: 0.240\n",
      "Got 382 / 495 with accuracy 77.17\n",
      "[171,     5] loss: 0.151\n",
      "[171,    10] loss: 0.187\n",
      "[171,    15] loss: 0.159\n",
      "Got 375 / 495 with accuracy 75.76\n",
      "[172,     5] loss: 0.187\n",
      "[172,    10] loss: 0.162\n",
      "[172,    15] loss: 0.157\n",
      "Got 398 / 495 with accuracy 80.40\n",
      "[173,     5] loss: 0.212\n",
      "[173,    10] loss: 0.154\n",
      "[173,    15] loss: 0.141\n",
      "Got 384 / 495 with accuracy 77.58\n",
      "[174,     5] loss: 0.158\n",
      "[174,    10] loss: 0.165\n",
      "[174,    15] loss: 0.200\n",
      "Got 335 / 495 with accuracy 67.68\n",
      "[175,     5] loss: 0.222\n",
      "[175,    10] loss: 0.162\n",
      "[175,    15] loss: 0.172\n",
      "Got 386 / 495 with accuracy 77.98\n",
      "[176,     5] loss: 0.207\n",
      "[176,    10] loss: 0.165\n",
      "[176,    15] loss: 0.134\n",
      "Got 334 / 495 with accuracy 67.47\n",
      "[177,     5] loss: 0.175\n",
      "[177,    10] loss: 0.177\n",
      "[177,    15] loss: 0.136\n",
      "Got 354 / 495 with accuracy 71.52\n",
      "[178,     5] loss: 0.165\n",
      "[178,    10] loss: 0.160\n",
      "[178,    15] loss: 0.185\n",
      "Got 339 / 495 with accuracy 68.48\n",
      "[179,     5] loss: 0.209\n",
      "[179,    10] loss: 0.140\n",
      "[179,    15] loss: 0.157\n",
      "Got 390 / 495 with accuracy 78.79\n",
      "[180,     5] loss: 0.179\n",
      "[180,    10] loss: 0.179\n",
      "[180,    15] loss: 0.174\n",
      "Got 358 / 495 with accuracy 72.32\n",
      "[181,     5] loss: 0.167\n",
      "[181,    10] loss: 0.219\n",
      "[181,    15] loss: 0.220\n",
      "Got 340 / 495 with accuracy 68.69\n",
      "[182,     5] loss: 0.237\n",
      "[182,    10] loss: 0.223\n",
      "[182,    15] loss: 0.299\n",
      "Got 327 / 495 with accuracy 66.06\n",
      "[183,     5] loss: 0.173\n",
      "[183,    10] loss: 0.204\n",
      "[183,    15] loss: 0.133\n",
      "Got 382 / 495 with accuracy 77.17\n",
      "[184,     5] loss: 0.143\n",
      "[184,    10] loss: 0.152\n",
      "[184,    15] loss: 0.207\n",
      "Got 360 / 495 with accuracy 72.73\n",
      "[185,     5] loss: 0.161\n",
      "[185,    10] loss: 0.150\n",
      "[185,    15] loss: 0.125\n",
      "Got 356 / 495 with accuracy 71.92\n",
      "[186,     5] loss: 0.119\n",
      "[186,    10] loss: 0.132\n",
      "[186,    15] loss: 0.133\n",
      "Got 377 / 495 with accuracy 76.16\n",
      "[187,     5] loss: 0.105\n",
      "[187,    10] loss: 0.177\n",
      "[187,    15] loss: 0.130\n",
      "Got 385 / 495 with accuracy 77.78\n",
      "[188,     5] loss: 0.183\n",
      "[188,    10] loss: 0.109\n",
      "[188,    15] loss: 0.148\n",
      "Got 342 / 495 with accuracy 69.09\n",
      "[189,     5] loss: 0.138\n",
      "[189,    10] loss: 0.134\n",
      "[189,    15] loss: 0.162\n",
      "Got 380 / 495 with accuracy 76.77\n",
      "[190,     5] loss: 0.155\n",
      "[190,    10] loss: 0.113\n",
      "[190,    15] loss: 0.141\n",
      "Got 380 / 495 with accuracy 76.77\n",
      "[191,     5] loss: 0.111\n",
      "[191,    10] loss: 0.193\n",
      "[191,    15] loss: 0.131\n",
      "Got 260 / 495 with accuracy 52.53\n",
      "[192,     5] loss: 0.142\n",
      "[192,    10] loss: 0.143\n",
      "[192,    15] loss: 0.132\n",
      "Got 350 / 495 with accuracy 70.71\n",
      "[193,     5] loss: 0.082\n",
      "[193,    10] loss: 0.088\n",
      "[193,    15] loss: 0.172\n",
      "Got 358 / 495 with accuracy 72.32\n",
      "[194,     5] loss: 0.095\n",
      "[194,    10] loss: 0.162\n",
      "[194,    15] loss: 0.146\n",
      "Got 363 / 495 with accuracy 73.33\n",
      "[195,     5] loss: 0.275\n",
      "[195,    10] loss: 0.227\n",
      "[195,    15] loss: 0.150\n",
      "Got 360 / 495 with accuracy 72.73\n",
      "[196,     5] loss: 0.137\n",
      "[196,    10] loss: 0.212\n",
      "[196,    15] loss: 0.149\n",
      "Got 384 / 495 with accuracy 77.58\n",
      "[197,     5] loss: 0.200\n",
      "[197,    10] loss: 0.161\n",
      "[197,    15] loss: 0.160\n",
      "Got 344 / 495 with accuracy 69.49\n",
      "[198,     5] loss: 0.127\n",
      "[198,    10] loss: 0.197\n",
      "[198,    15] loss: 0.136\n",
      "Got 372 / 495 with accuracy 75.15\n",
      "[199,     5] loss: 0.124\n",
      "[199,    10] loss: 0.155\n",
      "[199,    15] loss: 0.167\n",
      "Got 373 / 495 with accuracy 75.35\n",
      "[200,     5] loss: 0.195\n",
      "[200,    10] loss: 0.239\n",
      "[200,    15] loss: 0.167\n",
      "Got 385 / 495 with accuracy 77.78\n",
      "[201,     5] loss: 0.194\n",
      "[201,    10] loss: 0.151\n",
      "[201,    15] loss: 0.131\n",
      "Got 395 / 495 with accuracy 79.80\n",
      "[202,     5] loss: 0.130\n",
      "[202,    10] loss: 0.101\n",
      "[202,    15] loss: 0.089\n",
      "Got 383 / 495 with accuracy 77.37\n",
      "[203,     5] loss: 0.069\n",
      "[203,    10] loss: 0.072\n",
      "[203,    15] loss: 0.100\n",
      "Got 383 / 495 with accuracy 77.37\n",
      "[204,     5] loss: 0.091\n",
      "[204,    10] loss: 0.068\n",
      "[204,    15] loss: 0.110\n",
      "Got 379 / 495 with accuracy 76.57\n",
      "[205,     5] loss: 0.070\n",
      "[205,    10] loss: 0.111\n",
      "[205,    15] loss: 0.068\n",
      "Got 409 / 495 with accuracy 82.63\n",
      "[206,     5] loss: 0.096\n",
      "[206,    10] loss: 0.093\n",
      "[206,    15] loss: 0.082\n",
      "Got 396 / 495 with accuracy 80.00\n",
      "[207,     5] loss: 0.094\n",
      "[207,    10] loss: 0.099\n",
      "[207,    15] loss: 0.091\n",
      "Got 395 / 495 with accuracy 79.80\n",
      "[208,     5] loss: 0.082\n",
      "[208,    10] loss: 0.068\n",
      "[208,    15] loss: 0.097\n",
      "Got 393 / 495 with accuracy 79.39\n",
      "[209,     5] loss: 0.066\n",
      "[209,    10] loss: 0.065\n",
      "[209,    15] loss: 0.088\n",
      "Got 387 / 495 with accuracy 78.18\n",
      "[210,     5] loss: 0.119\n",
      "[210,    10] loss: 0.114\n",
      "[210,    15] loss: 0.088\n",
      "Got 379 / 495 with accuracy 76.57\n",
      "[211,     5] loss: 0.071\n",
      "[211,    10] loss: 0.085\n",
      "[211,    15] loss: 0.099\n",
      "Got 388 / 495 with accuracy 78.38\n",
      "[212,     5] loss: 0.069\n",
      "[212,    10] loss: 0.105\n",
      "[212,    15] loss: 0.088\n",
      "Got 385 / 495 with accuracy 77.78\n",
      "[213,     5] loss: 0.074\n",
      "[213,    10] loss: 0.079\n",
      "[213,    15] loss: 0.091\n",
      "Got 375 / 495 with accuracy 75.76\n",
      "[214,     5] loss: 0.067\n",
      "[214,    10] loss: 0.071\n",
      "[214,    15] loss: 0.097\n",
      "Got 389 / 495 with accuracy 78.59\n",
      "[215,     5] loss: 0.068\n",
      "[215,    10] loss: 0.057\n",
      "[215,    15] loss: 0.078\n",
      "Got 405 / 495 with accuracy 81.82\n",
      "[216,     5] loss: 0.050\n",
      "[216,    10] loss: 0.083\n",
      "[216,    15] loss: 0.074\n",
      "Got 389 / 495 with accuracy 78.59\n",
      "[217,     5] loss: 0.064\n",
      "[217,    10] loss: 0.056\n",
      "[217,    15] loss: 0.059\n",
      "Got 375 / 495 with accuracy 75.76\n",
      "[218,     5] loss: 0.056\n",
      "[218,    10] loss: 0.078\n",
      "[218,    15] loss: 0.055\n",
      "Got 382 / 495 with accuracy 77.17\n",
      "[219,     5] loss: 0.059\n",
      "[219,    10] loss: 0.044\n",
      "[219,    15] loss: 0.067\n",
      "Got 383 / 495 with accuracy 77.37\n",
      "[220,     5] loss: 0.061\n",
      "[220,    10] loss: 0.064\n",
      "[220,    15] loss: 0.065\n",
      "Got 380 / 495 with accuracy 76.77\n",
      "[221,     5] loss: 0.061\n",
      "[221,    10] loss: 0.085\n",
      "[221,    15] loss: 0.085\n",
      "Got 386 / 495 with accuracy 77.98\n",
      "[222,     5] loss: 0.043\n",
      "[222,    10] loss: 0.059\n",
      "[222,    15] loss: 0.092\n",
      "Got 388 / 495 with accuracy 78.38\n",
      "[223,     5] loss: 0.096\n",
      "[223,    10] loss: 0.077\n",
      "[223,    15] loss: 0.065\n",
      "Got 391 / 495 with accuracy 78.99\n",
      "[224,     5] loss: 0.081\n",
      "[224,    10] loss: 0.093\n",
      "[224,    15] loss: 0.092\n",
      "Got 380 / 495 with accuracy 76.77\n",
      "[225,     5] loss: 0.066\n",
      "[225,    10] loss: 0.068\n",
      "[225,    15] loss: 0.065\n",
      "Got 365 / 495 with accuracy 73.74\n",
      "[226,     5] loss: 0.080\n",
      "[226,    10] loss: 0.074\n",
      "[226,    15] loss: 0.111\n",
      "Got 379 / 495 with accuracy 76.57\n",
      "[227,     5] loss: 0.076\n",
      "[227,    10] loss: 0.056\n",
      "[227,    15] loss: 0.043\n",
      "Got 391 / 495 with accuracy 78.99\n",
      "[228,     5] loss: 0.075\n",
      "[228,    10] loss: 0.076\n",
      "[228,    15] loss: 0.067\n",
      "Got 379 / 495 with accuracy 76.57\n",
      "[229,     5] loss: 0.067\n",
      "[229,    10] loss: 0.100\n",
      "[229,    15] loss: 0.055\n",
      "Got 371 / 495 with accuracy 74.95\n",
      "[230,     5] loss: 0.075\n",
      "[230,    10] loss: 0.058\n",
      "[230,    15] loss: 0.047\n",
      "Got 397 / 495 with accuracy 80.20\n",
      "[231,     5] loss: 0.054\n",
      "[231,    10] loss: 0.065\n",
      "[231,    15] loss: 0.080\n",
      "Got 395 / 495 with accuracy 79.80\n",
      "[232,     5] loss: 0.053\n",
      "[232,    10] loss: 0.050\n",
      "[232,    15] loss: 0.061\n",
      "Got 399 / 495 with accuracy 80.61\n",
      "[233,     5] loss: 0.075\n",
      "[233,    10] loss: 0.056\n",
      "[233,    15] loss: 0.055\n",
      "Got 402 / 495 with accuracy 81.21\n",
      "[234,     5] loss: 0.056\n",
      "[234,    10] loss: 0.069\n",
      "[234,    15] loss: 0.039\n",
      "Got 381 / 495 with accuracy 76.97\n",
      "[235,     5] loss: 0.054\n",
      "[235,    10] loss: 0.050\n",
      "[235,    15] loss: 0.069\n",
      "Got 398 / 495 with accuracy 80.40\n",
      "[236,     5] loss: 0.064\n",
      "[236,    10] loss: 0.051\n",
      "[236,    15] loss: 0.059\n",
      "Got 394 / 495 with accuracy 79.60\n",
      "[237,     5] loss: 0.063\n",
      "[237,    10] loss: 0.050\n",
      "[237,    15] loss: 0.063\n",
      "Got 318 / 495 with accuracy 64.24\n",
      "[238,     5] loss: 0.087\n",
      "[238,    10] loss: 0.066\n",
      "[238,    15] loss: 0.090\n",
      "Got 354 / 495 with accuracy 71.52\n",
      "[239,     5] loss: 0.052\n",
      "[239,    10] loss: 0.063\n",
      "[239,    15] loss: 0.073\n",
      "Got 383 / 495 with accuracy 77.37\n",
      "[240,     5] loss: 0.057\n",
      "[240,    10] loss: 0.045\n",
      "[240,    15] loss: 0.058\n",
      "Got 393 / 495 with accuracy 79.39\n",
      "[241,     5] loss: 0.054\n",
      "[241,    10] loss: 0.066\n",
      "[241,    15] loss: 0.063\n",
      "Got 358 / 495 with accuracy 72.32\n",
      "[242,     5] loss: 0.049\n",
      "[242,    10] loss: 0.050\n",
      "[242,    15] loss: 0.071\n",
      "Got 387 / 495 with accuracy 78.18\n",
      "[243,     5] loss: 0.059\n",
      "[243,    10] loss: 0.050\n",
      "[243,    15] loss: 0.059\n",
      "Got 396 / 495 with accuracy 80.00\n",
      "[244,     5] loss: 0.053\n",
      "[244,    10] loss: 0.046\n",
      "[244,    15] loss: 0.061\n",
      "Got 370 / 495 with accuracy 74.75\n",
      "[245,     5] loss: 0.054\n",
      "[245,    10] loss: 0.073\n",
      "[245,    15] loss: 0.088\n",
      "Got 390 / 495 with accuracy 78.79\n",
      "[246,     5] loss: 0.042\n",
      "[246,    10] loss: 0.072\n",
      "[246,    15] loss: 0.062\n",
      "Got 366 / 495 with accuracy 73.94\n",
      "[247,     5] loss: 0.080\n",
      "[247,    10] loss: 0.060\n",
      "[247,    15] loss: 0.071\n",
      "Got 378 / 495 with accuracy 76.36\n",
      "[248,     5] loss: 0.087\n",
      "[248,    10] loss: 0.058\n",
      "[248,    15] loss: 0.069\n",
      "Got 384 / 495 with accuracy 77.58\n",
      "[249,     5] loss: 0.072\n",
      "[249,    10] loss: 0.082\n",
      "[249,    15] loss: 0.072\n",
      "Got 399 / 495 with accuracy 80.61\n",
      "[250,     5] loss: 0.081\n",
      "[250,    10] loss: 0.060\n",
      "[250,    15] loss: 0.070\n",
      "Got 380 / 495 with accuracy 76.77\n",
      "[251,     5] loss: 0.058\n",
      "[251,    10] loss: 0.054\n",
      "[251,    15] loss: 0.067\n",
      "Got 379 / 495 with accuracy 76.57\n",
      "[252,     5] loss: 0.048\n",
      "[252,    10] loss: 0.058\n",
      "[252,    15] loss: 0.046\n",
      "Got 388 / 495 with accuracy 78.38\n",
      "[253,     5] loss: 0.066\n",
      "[253,    10] loss: 0.066\n",
      "[253,    15] loss: 0.081\n",
      "Got 388 / 495 with accuracy 78.38\n",
      "[254,     5] loss: 0.063\n",
      "[254,    10] loss: 0.053\n",
      "[254,    15] loss: 0.055\n",
      "Got 378 / 495 with accuracy 76.36\n",
      "[255,     5] loss: 0.047\n",
      "[255,    10] loss: 0.057\n",
      "[255,    15] loss: 0.055\n",
      "Got 388 / 495 with accuracy 78.38\n",
      "[256,     5] loss: 0.049\n",
      "[256,    10] loss: 0.086\n",
      "[256,    15] loss: 0.045\n",
      "Got 382 / 495 with accuracy 77.17\n",
      "[257,     5] loss: 0.038\n",
      "[257,    10] loss: 0.048\n",
      "[257,    15] loss: 0.053\n",
      "Got 399 / 495 with accuracy 80.61\n",
      "[258,     5] loss: 0.056\n",
      "[258,    10] loss: 0.091\n",
      "[258,    15] loss: 0.079\n",
      "Got 358 / 495 with accuracy 72.32\n",
      "[259,     5] loss: 0.070\n",
      "[259,    10] loss: 0.057\n",
      "[259,    15] loss: 0.075\n",
      "Got 390 / 495 with accuracy 78.79\n",
      "[260,     5] loss: 0.075\n",
      "[260,    10] loss: 0.099\n",
      "[260,    15] loss: 0.105\n",
      "Got 378 / 495 with accuracy 76.36\n",
      "[261,     5] loss: 0.075\n",
      "[261,    10] loss: 0.067\n",
      "[261,    15] loss: 0.056\n",
      "Got 382 / 495 with accuracy 77.17\n",
      "[262,     5] loss: 0.066\n",
      "[262,    10] loss: 0.064\n",
      "[262,    15] loss: 0.040\n",
      "Got 380 / 495 with accuracy 76.77\n",
      "[263,     5] loss: 0.026\n",
      "[263,    10] loss: 0.078\n",
      "[263,    15] loss: 0.060\n",
      "Got 390 / 495 with accuracy 78.79\n",
      "[264,     5] loss: 0.059\n",
      "[264,    10] loss: 0.059\n",
      "[264,    15] loss: 0.061\n",
      "Got 374 / 495 with accuracy 75.56\n",
      "[265,     5] loss: 0.044\n",
      "[265,    10] loss: 0.068\n",
      "[265,    15] loss: 0.042\n",
      "Got 403 / 495 with accuracy 81.41\n",
      "[266,     5] loss: 0.051\n",
      "[266,    10] loss: 0.085\n",
      "[266,    15] loss: 0.044\n",
      "Got 387 / 495 with accuracy 78.18\n",
      "[267,     5] loss: 0.043\n",
      "[267,    10] loss: 0.058\n",
      "[267,    15] loss: 0.062\n",
      "Got 385 / 495 with accuracy 77.78\n",
      "[268,     5] loss: 0.057\n",
      "[268,    10] loss: 0.083\n",
      "[268,    15] loss: 0.050\n",
      "Got 375 / 495 with accuracy 75.76\n",
      "[269,     5] loss: 0.047\n",
      "[269,    10] loss: 0.053\n",
      "[269,    15] loss: 0.080\n",
      "Got 385 / 495 with accuracy 77.78\n",
      "[270,     5] loss: 0.072\n",
      "[270,    10] loss: 0.059\n",
      "[270,    15] loss: 0.049\n",
      "Got 383 / 495 with accuracy 77.37\n",
      "[271,     5] loss: 0.036\n",
      "[271,    10] loss: 0.054\n",
      "[271,    15] loss: 0.036\n",
      "Got 394 / 495 with accuracy 79.60\n",
      "[272,     5] loss: 0.029\n",
      "[272,    10] loss: 0.061\n",
      "[272,    15] loss: 0.051\n",
      "Got 395 / 495 with accuracy 79.80\n",
      "[273,     5] loss: 0.058\n",
      "[273,    10] loss: 0.053\n",
      "[273,    15] loss: 0.059\n",
      "Got 392 / 495 with accuracy 79.19\n",
      "[274,     5] loss: 0.053\n",
      "[274,    10] loss: 0.077\n",
      "[274,    15] loss: 0.084\n",
      "Got 390 / 495 with accuracy 78.79\n",
      "[275,     5] loss: 0.061\n",
      "[275,    10] loss: 0.042\n",
      "[275,    15] loss: 0.030\n",
      "Got 381 / 495 with accuracy 76.97\n",
      "[276,     5] loss: 0.053\n",
      "[276,    10] loss: 0.065\n",
      "[276,    15] loss: 0.063\n",
      "Got 372 / 495 with accuracy 75.15\n",
      "[277,     5] loss: 0.054\n",
      "[277,    10] loss: 0.069\n",
      "[277,    15] loss: 0.074\n",
      "Got 380 / 495 with accuracy 76.77\n",
      "[278,     5] loss: 0.079\n",
      "[278,    10] loss: 0.093\n",
      "[278,    15] loss: 0.082\n",
      "Got 369 / 495 with accuracy 74.55\n",
      "[279,     5] loss: 0.041\n",
      "[279,    10] loss: 0.072\n",
      "[279,    15] loss: 0.051\n",
      "Got 371 / 495 with accuracy 74.95\n",
      "[280,     5] loss: 0.034\n",
      "[280,    10] loss: 0.071\n",
      "[280,    15] loss: 0.050\n",
      "Got 395 / 495 with accuracy 79.80\n",
      "[281,     5] loss: 0.066\n",
      "[281,    10] loss: 0.059\n",
      "[281,    15] loss: 0.085\n",
      "Got 399 / 495 with accuracy 80.61\n",
      "[282,     5] loss: 0.038\n",
      "[282,    10] loss: 0.052\n",
      "[282,    15] loss: 0.083\n",
      "Got 388 / 495 with accuracy 78.38\n",
      "[283,     5] loss: 0.041\n",
      "[283,    10] loss: 0.075\n",
      "[283,    15] loss: 0.065\n",
      "Got 381 / 495 with accuracy 76.97\n",
      "[284,     5] loss: 0.054\n",
      "[284,    10] loss: 0.066\n",
      "[284,    15] loss: 0.040\n",
      "Got 384 / 495 with accuracy 77.58\n",
      "[285,     5] loss: 0.040\n",
      "[285,    10] loss: 0.067\n",
      "[285,    15] loss: 0.047\n",
      "Got 384 / 495 with accuracy 77.58\n",
      "[286,     5] loss: 0.030\n",
      "[286,    10] loss: 0.045\n",
      "[286,    15] loss: 0.036\n",
      "Got 385 / 495 with accuracy 77.78\n",
      "[287,     5] loss: 0.058\n",
      "[287,    10] loss: 0.039\n",
      "[287,    15] loss: 0.081\n",
      "Got 395 / 495 with accuracy 79.80\n",
      "[288,     5] loss: 0.028\n",
      "[288,    10] loss: 0.066\n",
      "[288,    15] loss: 0.043\n",
      "Got 397 / 495 with accuracy 80.20\n",
      "[289,     5] loss: 0.057\n",
      "[289,    10] loss: 0.061\n",
      "[289,    15] loss: 0.069\n",
      "Got 388 / 495 with accuracy 78.38\n",
      "[290,     5] loss: 0.058\n",
      "[290,    10] loss: 0.065\n",
      "[290,    15] loss: 0.052\n",
      "Got 369 / 495 with accuracy 74.55\n",
      "[291,     5] loss: 0.049\n",
      "[291,    10] loss: 0.037\n",
      "[291,    15] loss: 0.073\n",
      "Got 389 / 495 with accuracy 78.59\n",
      "[292,     5] loss: 0.055\n",
      "[292,    10] loss: 0.072\n",
      "[292,    15] loss: 0.067\n",
      "Got 374 / 495 with accuracy 75.56\n",
      "[293,     5] loss: 0.045\n",
      "[293,    10] loss: 0.056\n",
      "[293,    15] loss: 0.043\n",
      "Got 380 / 495 with accuracy 76.77\n",
      "[294,     5] loss: 0.067\n",
      "[294,    10] loss: 0.055\n",
      "[294,    15] loss: 0.066\n",
      "Got 386 / 495 with accuracy 77.98\n",
      "[295,     5] loss: 0.078\n",
      "[295,    10] loss: 0.082\n",
      "[295,    15] loss: 0.061\n",
      "Got 377 / 495 with accuracy 76.16\n",
      "[296,     5] loss: 0.049\n",
      "[296,    10] loss: 0.044\n",
      "[296,    15] loss: 0.069\n",
      "Got 394 / 495 with accuracy 79.60\n",
      "[297,     5] loss: 0.053\n",
      "[297,    10] loss: 0.064\n",
      "[297,    15] loss: 0.060\n",
      "Got 359 / 495 with accuracy 72.53\n",
      "[298,     5] loss: 0.047\n",
      "[298,    10] loss: 0.090\n",
      "[298,    15] loss: 0.045\n",
      "Got 393 / 495 with accuracy 79.39\n",
      "[299,     5] loss: 0.074\n",
      "[299,    10] loss: 0.078\n",
      "[299,    15] loss: 0.059\n",
      "Got 357 / 495 with accuracy 72.12\n",
      "[300,     5] loss: 0.041\n",
      "[300,    10] loss: 0.044\n",
      "[300,    15] loss: 0.054\n",
      "Got 379 / 495 with accuracy 76.57\n",
      "Finished Training\n",
      "Saving best model...\n",
      "Saved!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 5643<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.10MB of 0.10MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/matt/Work/MRes-Project/laser-trees/notebooks/wandb/run-20210523_001501-vaqkzncv/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/matt/Work/MRes-Project/laser-trees/notebooks/wandb/run-20210523_001501-vaqkzncv/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Train Loss</td><td>0.33817</td></tr><tr><td>Validation Loss</td><td>1.40908</td></tr><tr><td>Train Accuracy</td><td>0.97226</td></tr><tr><td>Validation Accuracy</td><td>0.76566</td></tr><tr><td>Learning Rate</td><td>0.00013</td></tr><tr><td>_step</td><td>299</td></tr><tr><td>_runtime</td><td>34071</td></tr><tr><td>_timestamp</td><td>1621759372</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Train Loss</td><td>▆▄█▅▄▅▄▃█▅▃▃▃▄▄▃▂▁▃▁▂▂▂▂▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Validation Loss</td><td>▄▂▆▂▁▃▂▁█▄▃▃▃▄▄▃▂▂▅▂▅▄▃▆▅▄▃▃▃▃▄▃▃▃▄▃▄▄▄▅</td></tr><tr><td>Train Accuracy</td><td>▂▄▂▄▅▄▄▆▁▄▅▅▅▅▅▆▇█▆█▆▇▇▆▆▇██████████████</td></tr><tr><td>Validation Accuracy</td><td>▃▆▄▅▇▆▇▇▁▄▆▆▆▅▆▇▇▇▅█▅▇▇▆▇▆▇██▇▇█▇█▇▇▇▇▇▇</td></tr><tr><td>Learning Rate</td><td>██████████████▃▃▃▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">worthy-field-77</strong>: <a href=\"https://wandb.ai/mja2106/laser-trees/runs/vaqkzncv\" target=\"_blank\">https://wandb.ai/mja2106/laser-trees/runs/vaqkzncv</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#wandb.watch(model)\n",
    "best_acc = 0\n",
    "for epoch in range(config.epochs):  # loop over the dataset multiple times\n",
    "    \n",
    "    #Training loop============================================\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        depth_images = data['depth_images']\n",
    "        labels = data['labels']\n",
    "\n",
    "        depth_images = depth_images.to(device=device)\n",
    "        labels = labels.to(device=device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(depth_images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 5 == 4:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2))\n",
    "            running_loss = 0.0\n",
    "                \n",
    "    #Test loop================================================\n",
    "    num_train_correct = 0\n",
    "    num_train_samples = 0\n",
    "    \n",
    "    num_val_correct = 0\n",
    "    num_val_samples = 0\n",
    "    \n",
    "    running_train_loss = 0\n",
    "    running_val_loss = 0\n",
    "    \n",
    "    model.eval()  \n",
    "    with torch.no_grad():\n",
    "        #Train set eval==============\n",
    "        for data in train_loader:\n",
    "            depth_images = data['depth_images']\n",
    "            labels = data['labels']\n",
    "\n",
    "            depth_images = depth_images.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "            \n",
    "            scores = model(depth_images)\n",
    "            _, predictions = scores.max(1)\n",
    "            num_train_correct += (predictions == labels).sum()\n",
    "            num_train_samples += predictions.size(0)\n",
    "            \n",
    "            running_train_loss += loss_fn(scores, labels)\n",
    "        \n",
    "        train_acc = float(num_train_correct)/float(num_train_samples)\n",
    "        train_loss = running_train_loss/len(validation_loader)\n",
    "        \n",
    "        #Test set eval===============\n",
    "        for data in validation_loader:\n",
    "            depth_images = data['depth_images']\n",
    "            labels = data['labels']\n",
    "\n",
    "            depth_images = depth_images.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "            \n",
    "            scores = model(depth_images)\n",
    "            _, predictions = scores.max(1)\n",
    "            num_val_correct += (predictions == labels).sum()\n",
    "            num_val_samples += predictions.size(0)\n",
    "            \n",
    "            running_val_loss += loss_fn(scores, labels)\n",
    "        \n",
    "        val_acc = float(num_val_correct)/float(num_val_samples)\n",
    "        val_loss = running_val_loss/len(validation_loader)\n",
    "        \n",
    "        print(f'Got {num_val_correct} / {num_val_samples} with accuracy {val_acc*100:.2f}')\n",
    "        \n",
    "        if val_acc > best_acc:\n",
    "            best_model_state = copy.deepcopy(model.state_dict())\n",
    "            best_acc = val_acc\n",
    "        \n",
    "        wandb.log({\n",
    "            \"Train Loss\":train_loss,\n",
    "            \"Validation Loss\":val_loss,\n",
    "            \"Train Accuracy\":train_acc,\n",
    "            \"Validation Accuracy\":val_acc,\n",
    "            \"Learning Rate\":optimizer.param_groups[0]['lr']\n",
    "            })\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "print('Saving best model...')\n",
    "torch.save(best_model_state,\n",
    "           '{model_dir}/{fname}.pt'.format(\n",
    "               model_dir=model_dir,\n",
    "               fname=experiment_name+'_best.pt')\n",
    "          )\n",
    "print('Saved!')\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb496f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8262626262626263"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffa349b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
