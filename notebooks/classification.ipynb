{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68fb7b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "pdir = os.path.dirname(os.getcwd())\n",
    "sys.path.append(pdir)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import wandb\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import utils\n",
    "from simpleview_pytorch import SimpleView\n",
    "\n",
    "from torch.utils.data.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd25fa53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmja2106\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6de60649",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54473f98",
   "metadata": {},
   "source": [
    "### Load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36691333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEFAG     1116\n",
      "PINNIG      581\n",
      "QUEILE      364\n",
      "PINSYL      277\n",
      "PINPIN      140\n",
      "JUNIPE        2\n",
      "NA            2\n",
      "QUERCUS       2\n",
      "DEAD          1\n",
      "Name: sp, dtype: int64\n",
      "Species:  ['DEAD', 'JUNIPE', 'NA', 'PINNIG', 'PINPIN', 'PINSYL', 'QUEFAG', 'QUEILE', 'QUERCUS']\n",
      "Labels:  tensor([8, 3, 6,  ..., 7, 3, 6])\n",
      "Total count:  2485\n"
     ]
    }
   ],
   "source": [
    "trees_data = torch.load('trees_128.pt')\n",
    "print(trees_data.counts)\n",
    "print('Species: ', trees_data.species)\n",
    "print('Labels: ', trees_data.labels)\n",
    "print('Total count: ', len(trees_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0c9f01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.28 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.15<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">fiery-elevator-20</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mja2106/laser-trees\" target=\"_blank\">https://wandb.ai/mja2106/laser-trees</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/mja2106/laser-trees/runs/2airkm60\" target=\"_blank\">https://wandb.ai/mja2106/laser-trees/runs/2airkm60</a><br/>\n",
       "                Run data is saved locally in <code>/home/matt/Work/MRes-Project/laser-trees/notebooks/wandb/run-20210503_110804-2airkm60</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = {\n",
    "    \"batch_size\":64,\n",
    "    \"validation_split\":.1,\n",
    "    \"shuffle_dataset\":True,\n",
    "    \"random_seed\":0,\n",
    "    \"learning_rate\":0.0005,\n",
    "    \"momentum\":0.9,\n",
    "    \"epochs\":100,\n",
    "    \"loss_fn\":\"cross-entropy\",\n",
    "    \"optimizer\":\"sgd\",\n",
    "    \"jitter\":False,\n",
    "    \"random_rotation\":False,\n",
    "    \"random_scaling\":False,\n",
    "    \"random_translation\":False,\n",
    "    \"voting\":\"None\",\n",
    "    \n",
    "    \"model\":\"SimpleView\",\n",
    "    \n",
    "    \"image_dim\":trees_data.image_dim,\n",
    "    \"camera_fov_deg\":trees_data.camera_fov_deg,\n",
    "    \"f\":trees_data.f,\n",
    "    \"camera_dist\":trees_data.camera_dist,\n",
    "    \"num_views\":trees_data.depth_images.shape[1],\n",
    "    \"depth_averaging\" = \"min\",\n",
    "    \n",
    "    \"species\":[\"QUEFAG\", \"PINNIG\", \"QUEILE\", \"PINSYL\", \"PINPIN\"]\n",
    "    \"data_resolution\":\"2.5cm\"\n",
    "}\n",
    "\n",
    "if trees_data.soft_min_k:\n",
    "    params[\"soft_min_k\"] = trees_data.soft_min_k\n",
    "\n",
    "experiment_name = wandb.util.generate_id()\n",
    "    \n",
    "run = wandb.init(\n",
    "    project='laser-trees',\n",
    "    group=experiment_name,\n",
    "    config=params)    \n",
    "\n",
    "config = wandb.config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a2cd55",
   "metadata": {},
   "source": [
    "#### Remove low-count species:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3dda6708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEFAG    1116\n",
      "PINNIG     581\n",
      "QUEILE     364\n",
      "PINSYL     277\n",
      "PINPIN     140\n",
      "Name: sp, dtype: int64\n",
      "Species:  ['PINNIG', 'PINPIN', 'PINSYL', 'QUEFAG', 'QUEILE']\n",
      "Labels:  tensor([0, 3, 3,  ..., 4, 0, 3])\n",
      "Total count:  2478\n"
     ]
    }
   ],
   "source": [
    "for specie in list(set(trees_data.species) - set(config.species)):\n",
    "    print(\"Removing: {}\".format(specie))\n",
    "    trees_data.remove_species(specie)\n",
    "    \n",
    "print(trees_data.counts)\n",
    "print('Species: ', trees_data.species)\n",
    "print('Labels: ', trees_data.labels)\n",
    "print('Total count: ', len(trees_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dbada1",
   "metadata": {},
   "source": [
    "#### Train-validation split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99f94d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(trees_data)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(config.validation_split * dataset_size))\n",
    "\n",
    "if config.shuffle_dataset :\n",
    "    np.random.seed(config.random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a620dfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trees_data, batch_size=config.batch_size, \n",
    "                                           sampler=train_sampler)\n",
    "validation_loader = torch.utils.data.DataLoader(trees_data, batch_size=config.batch_size,\n",
    "                                                sampler=valid_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9e1b0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run to print no. instances of each class\n",
    "if None:\n",
    "    for x in train_loader:\n",
    "        print(torch.unique(x['labels'], return_counts = True))\n",
    "    print()\n",
    "\n",
    "    for x in validation_loader:\n",
    "        print(torch.unique(x['labels'], return_counts = True))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631bb35a",
   "metadata": {},
   "source": [
    "### Define model, loss fn, optimiser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9fb357c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(config.species) == set(trees_data.species)\n",
    "\n",
    "if config.model==\"SimpleView\":\n",
    "    model = SimpleView(\n",
    "        num_views=config.num_views,\n",
    "        num_classes=len(config.species)\n",
    "    )\n",
    "\n",
    "model = model.to(device=device)\n",
    "\n",
    "if config.loss_fn==\"cross-entropy\":\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "if config.optimizer==\"sgd\":\n",
    "    optimizer = optim.SGD(model.parameters(), lr=config.learning_rate, momentum=config.momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2ffa13",
   "metadata": {},
   "source": [
    "### Train & Test Loops:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1fd94536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     5] loss: 4.299\n",
      "[1,    10] loss: 3.608\n",
      "[1,    15] loss: 3.536\n",
      "[1,    20] loss: 3.639\n",
      "[1,    25] loss: 3.550\n",
      "[1,    30] loss: 3.261\n",
      "[1,    35] loss: 3.505\n",
      "Got 109 / 247 with accuracy 44.13\n",
      "[2,     5] loss: 3.369\n",
      "[2,    10] loss: 3.411\n",
      "[2,    15] loss: 3.089\n",
      "[2,    20] loss: 3.026\n",
      "[2,    25] loss: 3.206\n",
      "[2,    30] loss: 3.172\n",
      "[2,    35] loss: 3.228\n",
      "Got 130 / 247 with accuracy 52.63\n",
      "[3,     5] loss: 2.869\n",
      "[3,    10] loss: 3.062\n",
      "[3,    15] loss: 3.109\n",
      "[3,    20] loss: 3.096\n",
      "[3,    25] loss: 2.946\n",
      "[3,    30] loss: 3.001\n",
      "[3,    35] loss: 3.043\n",
      "Got 132 / 247 with accuracy 53.44\n",
      "[4,     5] loss: 2.903\n",
      "[4,    10] loss: 2.778\n",
      "[4,    15] loss: 2.820\n",
      "[4,    20] loss: 2.951\n",
      "[4,    25] loss: 2.934\n",
      "[4,    30] loss: 2.911\n",
      "[4,    35] loss: 2.818\n",
      "Got 135 / 247 with accuracy 54.66\n",
      "[5,     5] loss: 2.767\n",
      "[5,    10] loss: 2.952\n",
      "[5,    15] loss: 2.746\n",
      "[5,    20] loss: 2.788\n",
      "[5,    25] loss: 2.720\n",
      "[5,    30] loss: 2.598\n",
      "[5,    35] loss: 2.667\n",
      "Got 144 / 247 with accuracy 58.30\n",
      "[6,     5] loss: 2.664\n",
      "[6,    10] loss: 2.618\n",
      "[6,    15] loss: 2.676\n",
      "[6,    20] loss: 2.739\n",
      "[6,    25] loss: 2.416\n",
      "[6,    30] loss: 2.690\n",
      "[6,    35] loss: 2.956\n",
      "Got 152 / 247 with accuracy 61.54\n",
      "[7,     5] loss: 2.699\n",
      "[7,    10] loss: 2.632\n",
      "[7,    15] loss: 2.449\n",
      "[7,    20] loss: 2.736\n",
      "[7,    25] loss: 2.625\n",
      "[7,    30] loss: 2.514\n",
      "[7,    35] loss: 2.665\n",
      "Got 145 / 247 with accuracy 58.70\n",
      "[8,     5] loss: 2.540\n",
      "[8,    10] loss: 2.656\n",
      "[8,    15] loss: 2.474\n",
      "[8,    20] loss: 2.383\n",
      "[8,    25] loss: 2.576\n",
      "[8,    30] loss: 2.509\n",
      "[8,    35] loss: 2.592\n",
      "Got 156 / 247 with accuracy 63.16\n",
      "[9,     5] loss: 2.391\n",
      "[9,    10] loss: 2.524\n",
      "[9,    15] loss: 2.646\n",
      "[9,    20] loss: 2.424\n",
      "[9,    25] loss: 2.490\n",
      "[9,    30] loss: 2.362\n",
      "[9,    35] loss: 2.413\n",
      "Got 158 / 247 with accuracy 63.97\n",
      "[10,     5] loss: 2.393\n",
      "[10,    10] loss: 2.413\n",
      "[10,    15] loss: 2.497\n",
      "[10,    20] loss: 2.309\n",
      "[10,    25] loss: 2.460\n",
      "[10,    30] loss: 2.447\n",
      "[10,    35] loss: 2.292\n",
      "Got 161 / 247 with accuracy 65.18\n",
      "[11,     5] loss: 2.316\n",
      "[11,    10] loss: 2.270\n",
      "[11,    15] loss: 2.315\n",
      "[11,    20] loss: 2.446\n",
      "[11,    25] loss: 2.426\n",
      "[11,    30] loss: 2.326\n",
      "[11,    35] loss: 2.313\n",
      "Got 162 / 247 with accuracy 65.59\n",
      "[12,     5] loss: 2.375\n",
      "[12,    10] loss: 2.399\n",
      "[12,    15] loss: 2.476\n",
      "[12,    20] loss: 2.324\n",
      "[12,    25] loss: 2.197\n",
      "[12,    30] loss: 2.156\n",
      "[12,    35] loss: 2.498\n",
      "Got 161 / 247 with accuracy 65.18\n",
      "[13,     5] loss: 2.324\n",
      "[13,    10] loss: 2.035\n",
      "[13,    15] loss: 2.159\n",
      "[13,    20] loss: 2.520\n",
      "[13,    25] loss: 2.221\n",
      "[13,    30] loss: 2.105\n",
      "[13,    35] loss: 2.358\n",
      "Got 162 / 247 with accuracy 65.59\n",
      "[14,     5] loss: 2.146\n",
      "[14,    10] loss: 2.226\n",
      "[14,    15] loss: 2.131\n",
      "[14,    20] loss: 2.298\n",
      "[14,    25] loss: 2.108\n",
      "[14,    30] loss: 2.263\n",
      "[14,    35] loss: 2.358\n",
      "Got 159 / 247 with accuracy 64.37\n",
      "[15,     5] loss: 2.177\n",
      "[15,    10] loss: 2.172\n",
      "[15,    15] loss: 2.134\n",
      "[15,    20] loss: 2.227\n",
      "[15,    25] loss: 2.161\n",
      "[15,    30] loss: 2.243\n",
      "[15,    35] loss: 2.148\n",
      "Got 162 / 247 with accuracy 65.59\n",
      "[16,     5] loss: 2.133\n",
      "[16,    10] loss: 2.151\n",
      "[16,    15] loss: 1.973\n",
      "[16,    20] loss: 2.316\n",
      "[16,    25] loss: 2.261\n",
      "[16,    30] loss: 1.864\n",
      "[16,    35] loss: 2.239\n",
      "Got 162 / 247 with accuracy 65.59\n",
      "[17,     5] loss: 2.084\n",
      "[17,    10] loss: 2.330\n",
      "[17,    15] loss: 2.074\n",
      "[17,    20] loss: 1.862\n",
      "[17,    25] loss: 2.145\n",
      "[17,    30] loss: 2.192\n",
      "[17,    35] loss: 1.973\n",
      "Got 161 / 247 with accuracy 65.18\n",
      "[18,     5] loss: 2.036\n",
      "[18,    10] loss: 2.072\n",
      "[18,    15] loss: 2.153\n",
      "[18,    20] loss: 2.116\n",
      "[18,    25] loss: 1.954\n",
      "[18,    30] loss: 1.887\n",
      "[18,    35] loss: 2.174\n",
      "Got 162 / 247 with accuracy 65.59\n",
      "[19,     5] loss: 2.054\n",
      "[19,    10] loss: 2.296\n",
      "[19,    15] loss: 1.877\n",
      "[19,    20] loss: 1.921\n",
      "[19,    25] loss: 1.954\n",
      "[19,    30] loss: 2.113\n",
      "[19,    35] loss: 2.037\n",
      "Got 159 / 247 with accuracy 64.37\n",
      "[20,     5] loss: 1.815\n",
      "[20,    10] loss: 1.878\n",
      "[20,    15] loss: 2.042\n",
      "[20,    20] loss: 2.023\n",
      "[20,    25] loss: 2.054\n",
      "[20,    30] loss: 2.022\n",
      "[20,    35] loss: 1.947\n",
      "Got 162 / 247 with accuracy 65.59\n",
      "[21,     5] loss: 2.218\n",
      "[21,    10] loss: 1.892\n",
      "[21,    15] loss: 1.859\n",
      "[21,    20] loss: 1.904\n",
      "[21,    25] loss: 2.071\n",
      "[21,    30] loss: 1.908\n",
      "[21,    35] loss: 1.758\n",
      "Got 159 / 247 with accuracy 64.37\n",
      "[22,     5] loss: 1.932\n",
      "[22,    10] loss: 1.766\n",
      "[22,    15] loss: 1.892\n",
      "[22,    20] loss: 1.803\n",
      "[22,    25] loss: 1.899\n",
      "[22,    30] loss: 2.018\n",
      "[22,    35] loss: 1.934\n",
      "Got 160 / 247 with accuracy 64.78\n",
      "[23,     5] loss: 1.924\n",
      "[23,    10] loss: 1.927\n",
      "[23,    15] loss: 1.769\n",
      "[23,    20] loss: 1.646\n",
      "[23,    25] loss: 1.818\n",
      "[23,    30] loss: 1.884\n",
      "[23,    35] loss: 1.941\n",
      "Got 155 / 247 with accuracy 62.75\n",
      "[24,     5] loss: 1.649\n",
      "[24,    10] loss: 1.856\n",
      "[24,    15] loss: 1.953\n",
      "[24,    20] loss: 1.837\n",
      "[24,    25] loss: 1.704\n",
      "[24,    30] loss: 1.850\n",
      "[24,    35] loss: 1.754\n",
      "Got 157 / 247 with accuracy 63.56\n",
      "[25,     5] loss: 1.608\n",
      "[25,    10] loss: 1.732\n",
      "[25,    15] loss: 1.781\n",
      "[25,    20] loss: 1.828\n",
      "[25,    25] loss: 1.689\n",
      "[25,    30] loss: 1.876\n",
      "[25,    35] loss: 1.799\n",
      "Got 162 / 247 with accuracy 65.59\n",
      "[26,     5] loss: 1.646\n",
      "[26,    10] loss: 1.775\n",
      "[26,    15] loss: 1.736\n",
      "[26,    20] loss: 1.606\n",
      "[26,    25] loss: 1.729\n",
      "[26,    30] loss: 1.756\n",
      "[26,    35] loss: 1.801\n",
      "Got 159 / 247 with accuracy 64.37\n",
      "[27,     5] loss: 1.732\n",
      "[27,    10] loss: 1.589\n",
      "[27,    15] loss: 1.747\n",
      "[27,    20] loss: 1.842\n",
      "[27,    25] loss: 1.696\n",
      "[27,    30] loss: 1.535\n",
      "[27,    35] loss: 1.821\n",
      "Got 160 / 247 with accuracy 64.78\n",
      "[28,     5] loss: 1.518\n",
      "[28,    10] loss: 1.723\n",
      "[28,    15] loss: 1.705\n",
      "[28,    20] loss: 1.802\n",
      "[28,    25] loss: 1.383\n",
      "[28,    30] loss: 1.759\n",
      "[28,    35] loss: 1.555\n",
      "Got 165 / 247 with accuracy 66.80\n",
      "[29,     5] loss: 1.507\n",
      "[29,    10] loss: 1.630\n",
      "[29,    15] loss: 1.501\n",
      "[29,    20] loss: 1.544\n",
      "[29,    25] loss: 1.681\n",
      "[29,    30] loss: 1.723\n",
      "[29,    35] loss: 1.464\n",
      "Got 161 / 247 with accuracy 65.18\n",
      "[30,     5] loss: 1.436\n",
      "[30,    10] loss: 1.514\n",
      "[30,    15] loss: 1.463\n",
      "[30,    20] loss: 1.621\n",
      "[30,    25] loss: 1.590\n",
      "[30,    30] loss: 1.393\n",
      "[30,    35] loss: 1.632\n",
      "Got 160 / 247 with accuracy 64.78\n",
      "[31,     5] loss: 1.485\n",
      "[31,    10] loss: 1.637\n",
      "[31,    15] loss: 1.513\n",
      "[31,    20] loss: 1.478\n",
      "[31,    25] loss: 1.448\n",
      "[31,    30] loss: 1.464\n",
      "[31,    35] loss: 1.467\n",
      "Got 164 / 247 with accuracy 66.40\n",
      "[32,     5] loss: 1.435\n",
      "[32,    10] loss: 1.499\n",
      "[32,    15] loss: 1.480\n",
      "[32,    20] loss: 1.501\n",
      "[32,    25] loss: 1.362\n",
      "[32,    30] loss: 1.408\n",
      "[32,    35] loss: 1.308\n",
      "Got 165 / 247 with accuracy 66.80\n",
      "[33,     5] loss: 1.332\n",
      "[33,    10] loss: 1.459\n",
      "[33,    15] loss: 1.390\n",
      "[33,    20] loss: 1.385\n",
      "[33,    25] loss: 1.339\n",
      "[33,    30] loss: 1.347\n",
      "[33,    35] loss: 1.506\n",
      "Got 167 / 247 with accuracy 67.61\n",
      "[34,     5] loss: 1.396\n",
      "[34,    10] loss: 1.417\n",
      "[34,    15] loss: 1.343\n",
      "[34,    20] loss: 1.417\n",
      "[34,    25] loss: 1.246\n",
      "[34,    30] loss: 1.335\n",
      "[34,    35] loss: 1.427\n",
      "Got 155 / 247 with accuracy 62.75\n",
      "[35,     5] loss: 1.279\n",
      "[35,    10] loss: 1.215\n",
      "[35,    15] loss: 1.296\n",
      "[35,    20] loss: 1.356\n",
      "[35,    25] loss: 1.247\n",
      "[35,    30] loss: 1.398\n",
      "[35,    35] loss: 1.323\n",
      "Got 162 / 247 with accuracy 65.59\n",
      "[36,     5] loss: 1.274\n",
      "[36,    10] loss: 1.210\n",
      "[36,    15] loss: 1.211\n",
      "[36,    20] loss: 1.121\n",
      "[36,    25] loss: 1.198\n",
      "[36,    30] loss: 1.361\n",
      "[36,    35] loss: 1.304\n",
      "Got 158 / 247 with accuracy 63.97\n",
      "[37,     5] loss: 1.277\n",
      "[37,    10] loss: 1.266\n",
      "[37,    15] loss: 1.276\n",
      "[37,    20] loss: 1.042\n",
      "[37,    25] loss: 1.157\n",
      "[37,    30] loss: 1.187\n",
      "[37,    35] loss: 1.248\n",
      "Got 165 / 247 with accuracy 66.80\n",
      "[38,     5] loss: 1.036\n",
      "[38,    10] loss: 1.177\n",
      "[38,    15] loss: 0.981\n",
      "[38,    20] loss: 1.111\n",
      "[38,    25] loss: 1.144\n",
      "[38,    30] loss: 1.249\n",
      "[38,    35] loss: 1.259\n",
      "Got 154 / 247 with accuracy 62.35\n",
      "[39,     5] loss: 1.096\n",
      "[39,    10] loss: 1.178\n",
      "[39,    15] loss: 1.134\n",
      "[39,    20] loss: 1.053\n",
      "[39,    25] loss: 1.108\n",
      "[39,    30] loss: 1.216\n",
      "[39,    35] loss: 1.063\n",
      "Got 166 / 247 with accuracy 67.21\n",
      "[40,     5] loss: 0.984\n",
      "[40,    10] loss: 0.973\n",
      "[40,    15] loss: 1.039\n",
      "[40,    20] loss: 1.060\n",
      "[40,    25] loss: 0.967\n",
      "[40,    30] loss: 1.259\n",
      "[40,    35] loss: 1.272\n",
      "Got 149 / 247 with accuracy 60.32\n",
      "[41,     5] loss: 1.088\n",
      "[41,    10] loss: 1.057\n",
      "[41,    15] loss: 0.962\n",
      "[41,    20] loss: 0.962\n",
      "[41,    25] loss: 1.047\n",
      "[41,    30] loss: 1.029\n",
      "[41,    35] loss: 1.004\n",
      "Got 166 / 247 with accuracy 67.21\n",
      "[42,     5] loss: 0.911\n",
      "[42,    10] loss: 0.962\n",
      "[42,    15] loss: 1.001\n",
      "[42,    20] loss: 0.964\n",
      "[42,    25] loss: 0.931\n",
      "[42,    30] loss: 1.068\n",
      "[42,    35] loss: 0.995\n",
      "Got 161 / 247 with accuracy 65.18\n",
      "[43,     5] loss: 0.989\n",
      "[43,    10] loss: 0.881\n",
      "[43,    15] loss: 0.894\n",
      "[43,    20] loss: 0.980\n",
      "[43,    25] loss: 0.991\n",
      "[43,    30] loss: 0.866\n",
      "[43,    35] loss: 0.987\n",
      "Got 164 / 247 with accuracy 66.40\n",
      "[44,     5] loss: 0.848\n",
      "[44,    10] loss: 0.910\n",
      "[44,    15] loss: 0.835\n",
      "[44,    20] loss: 0.928\n",
      "[44,    25] loss: 0.854\n",
      "[44,    30] loss: 0.923\n",
      "[44,    35] loss: 0.948\n",
      "Got 161 / 247 with accuracy 65.18\n",
      "[45,     5] loss: 0.763\n",
      "[45,    10] loss: 0.830\n",
      "[45,    15] loss: 0.862\n",
      "[45,    20] loss: 0.826\n",
      "[45,    25] loss: 0.878\n",
      "[45,    30] loss: 0.967\n",
      "[45,    35] loss: 0.868\n",
      "Got 150 / 247 with accuracy 60.73\n",
      "[46,     5] loss: 0.805\n",
      "[46,    10] loss: 0.769\n",
      "[46,    15] loss: 0.957\n",
      "[46,    20] loss: 0.768\n",
      "[46,    25] loss: 0.813\n",
      "[46,    30] loss: 0.821\n",
      "[46,    35] loss: 0.746\n",
      "Got 166 / 247 with accuracy 67.21\n",
      "[47,     5] loss: 0.781\n",
      "[47,    10] loss: 0.873\n",
      "[47,    15] loss: 0.770\n",
      "[47,    20] loss: 0.811\n",
      "[47,    25] loss: 0.698\n",
      "[47,    30] loss: 0.753\n",
      "[47,    35] loss: 0.887\n",
      "Got 163 / 247 with accuracy 65.99\n",
      "[48,     5] loss: 0.840\n",
      "[48,    10] loss: 0.763\n",
      "[48,    15] loss: 0.689\n",
      "[48,    20] loss: 0.667\n",
      "[48,    25] loss: 0.885\n",
      "[48,    30] loss: 0.816\n",
      "[48,    35] loss: 0.749\n",
      "Got 163 / 247 with accuracy 65.99\n",
      "[49,     5] loss: 0.722\n",
      "[49,    10] loss: 0.680\n",
      "[49,    15] loss: 0.651\n",
      "[49,    20] loss: 0.744\n",
      "[49,    25] loss: 0.696\n",
      "[49,    30] loss: 0.676\n",
      "[49,    35] loss: 0.798\n",
      "Got 157 / 247 with accuracy 63.56\n",
      "[50,     5] loss: 0.700\n",
      "[50,    10] loss: 0.719\n",
      "[50,    15] loss: 0.648\n",
      "[50,    20] loss: 0.639\n",
      "[50,    25] loss: 0.759\n",
      "[50,    30] loss: 0.690\n",
      "[50,    35] loss: 0.703\n",
      "Got 166 / 247 with accuracy 67.21\n",
      "[51,     5] loss: 0.632\n",
      "[51,    10] loss: 0.592\n",
      "[51,    15] loss: 0.681\n",
      "[51,    20] loss: 0.684\n",
      "[51,    25] loss: 0.680\n",
      "[51,    30] loss: 0.704\n",
      "[51,    35] loss: 0.651\n",
      "Got 165 / 247 with accuracy 66.80\n",
      "[52,     5] loss: 0.699\n",
      "[52,    10] loss: 0.701\n",
      "[52,    15] loss: 0.630\n",
      "[52,    20] loss: 0.633\n",
      "[52,    25] loss: 0.660\n",
      "[52,    30] loss: 0.528\n",
      "[52,    35] loss: 0.704\n",
      "Got 169 / 247 with accuracy 68.42\n",
      "[53,     5] loss: 0.572\n",
      "[53,    10] loss: 0.570\n",
      "[53,    15] loss: 0.523\n",
      "[53,    20] loss: 0.504\n",
      "[53,    25] loss: 0.706\n",
      "[53,    30] loss: 0.677\n",
      "[53,    35] loss: 0.609\n",
      "Got 169 / 247 with accuracy 68.42\n",
      "[54,     5] loss: 0.541\n",
      "[54,    10] loss: 0.631\n",
      "[54,    15] loss: 0.573\n",
      "[54,    20] loss: 0.589\n",
      "[54,    25] loss: 0.579\n",
      "[54,    30] loss: 0.554\n",
      "[54,    35] loss: 0.566\n",
      "Got 158 / 247 with accuracy 63.97\n",
      "[55,     5] loss: 0.566\n",
      "[55,    10] loss: 0.568\n",
      "[55,    15] loss: 0.561\n",
      "[55,    20] loss: 0.518\n",
      "[55,    25] loss: 0.523\n",
      "[55,    30] loss: 0.527\n",
      "[55,    35] loss: 0.512\n",
      "Got 152 / 247 with accuracy 61.54\n",
      "[56,     5] loss: 0.527\n",
      "[56,    10] loss: 0.454\n",
      "[56,    15] loss: 0.553\n",
      "[56,    20] loss: 0.508\n",
      "[56,    25] loss: 0.423\n",
      "[56,    30] loss: 0.487\n",
      "[56,    35] loss: 0.619\n",
      "Got 158 / 247 with accuracy 63.97\n",
      "[57,     5] loss: 0.448\n",
      "[57,    10] loss: 0.438\n",
      "[57,    15] loss: 0.483\n",
      "[57,    20] loss: 0.539\n",
      "[57,    25] loss: 0.505\n",
      "[57,    30] loss: 0.504\n",
      "[57,    35] loss: 0.507\n",
      "Got 152 / 247 with accuracy 61.54\n",
      "[58,     5] loss: 0.507\n",
      "[58,    10] loss: 0.450\n",
      "[58,    15] loss: 0.473\n",
      "[58,    20] loss: 0.495\n",
      "[58,    25] loss: 0.442\n",
      "[58,    30] loss: 0.415\n",
      "[58,    35] loss: 0.445\n",
      "Got 161 / 247 with accuracy 65.18\n",
      "[59,     5] loss: 0.433\n",
      "[59,    10] loss: 0.412\n",
      "[59,    15] loss: 0.431\n",
      "[59,    20] loss: 0.441\n",
      "[59,    25] loss: 0.449\n",
      "[59,    30] loss: 0.398\n",
      "[59,    35] loss: 0.462\n",
      "Got 167 / 247 with accuracy 67.61\n",
      "[60,     5] loss: 0.388\n",
      "[60,    10] loss: 0.402\n",
      "[60,    15] loss: 0.384\n",
      "[60,    20] loss: 0.389\n",
      "[60,    25] loss: 0.432\n",
      "[60,    30] loss: 0.408\n",
      "[60,    35] loss: 0.408\n",
      "Got 154 / 247 with accuracy 62.35\n",
      "[61,     5] loss: 0.404\n",
      "[61,    10] loss: 0.375\n",
      "[61,    15] loss: 0.389\n",
      "[61,    20] loss: 0.370\n",
      "[61,    25] loss: 0.406\n",
      "[61,    30] loss: 0.318\n",
      "[61,    35] loss: 0.402\n",
      "Got 153 / 247 with accuracy 61.94\n",
      "[62,     5] loss: 0.403\n",
      "[62,    10] loss: 0.316\n",
      "[62,    15] loss: 0.373\n",
      "[62,    20] loss: 0.329\n",
      "[62,    25] loss: 0.364\n",
      "[62,    30] loss: 0.387\n",
      "[62,    35] loss: 0.365\n",
      "Got 145 / 247 with accuracy 58.70\n",
      "[63,     5] loss: 0.293\n",
      "[63,    10] loss: 0.351\n",
      "[63,    15] loss: 0.398\n",
      "[63,    20] loss: 0.369\n",
      "[63,    25] loss: 0.313\n",
      "[63,    30] loss: 0.367\n",
      "[63,    35] loss: 0.374\n",
      "Got 152 / 247 with accuracy 61.54\n",
      "[64,     5] loss: 0.337\n",
      "[64,    10] loss: 0.367\n",
      "[64,    15] loss: 0.319\n",
      "[64,    20] loss: 0.324\n",
      "[64,    25] loss: 0.332\n",
      "[64,    30] loss: 0.266\n",
      "[64,    35] loss: 0.328\n",
      "Got 157 / 247 with accuracy 63.56\n",
      "[65,     5] loss: 0.279\n",
      "[65,    10] loss: 0.302\n",
      "[65,    15] loss: 0.272\n",
      "[65,    20] loss: 0.324\n",
      "[65,    25] loss: 0.327\n",
      "[65,    30] loss: 0.285\n",
      "[65,    35] loss: 0.312\n",
      "Got 157 / 247 with accuracy 63.56\n",
      "[66,     5] loss: 0.278\n",
      "[66,    10] loss: 0.252\n",
      "[66,    15] loss: 0.273\n",
      "[66,    20] loss: 0.322\n",
      "[66,    25] loss: 0.271\n",
      "[66,    30] loss: 0.290\n",
      "[66,    35] loss: 0.266\n",
      "Got 154 / 247 with accuracy 62.35\n",
      "[67,     5] loss: 0.242\n",
      "[67,    10] loss: 0.296\n",
      "[67,    15] loss: 0.227\n",
      "[67,    20] loss: 0.270\n",
      "[67,    25] loss: 0.276\n",
      "[67,    30] loss: 0.269\n",
      "[67,    35] loss: 0.247\n",
      "Got 154 / 247 with accuracy 62.35\n",
      "[68,     5] loss: 0.229\n",
      "[68,    10] loss: 0.224\n",
      "[68,    15] loss: 0.263\n",
      "[68,    20] loss: 0.263\n",
      "[68,    25] loss: 0.250\n",
      "[68,    30] loss: 0.238\n",
      "[68,    35] loss: 0.273\n",
      "Got 146 / 247 with accuracy 59.11\n",
      "[69,     5] loss: 0.247\n",
      "[69,    10] loss: 0.208\n",
      "[69,    15] loss: 0.251\n",
      "[69,    20] loss: 0.253\n",
      "[69,    25] loss: 0.261\n",
      "[69,    30] loss: 0.226\n",
      "[69,    35] loss: 0.228\n",
      "Got 162 / 247 with accuracy 65.59\n",
      "[70,     5] loss: 0.226\n",
      "[70,    10] loss: 0.205\n",
      "[70,    15] loss: 0.223\n",
      "[70,    20] loss: 0.198\n",
      "[70,    25] loss: 0.196\n",
      "[70,    30] loss: 0.235\n",
      "[70,    35] loss: 0.196\n",
      "Got 153 / 247 with accuracy 61.94\n",
      "[71,     5] loss: 0.186\n",
      "[71,    10] loss: 0.221\n",
      "[71,    15] loss: 0.192\n",
      "[71,    20] loss: 0.184\n",
      "[71,    25] loss: 0.186\n",
      "[71,    30] loss: 0.202\n",
      "[71,    35] loss: 0.228\n",
      "Got 154 / 247 with accuracy 62.35\n",
      "[72,     5] loss: 0.176\n",
      "[72,    10] loss: 0.202\n",
      "[72,    15] loss: 0.177\n",
      "[72,    20] loss: 0.233\n",
      "[72,    25] loss: 0.220\n",
      "[72,    30] loss: 0.202\n",
      "[72,    35] loss: 0.168\n",
      "Got 152 / 247 with accuracy 61.54\n",
      "[73,     5] loss: 0.146\n",
      "[73,    10] loss: 0.183\n",
      "[73,    15] loss: 0.187\n",
      "[73,    20] loss: 0.199\n",
      "[73,    25] loss: 0.154\n",
      "[73,    30] loss: 0.165\n",
      "[73,    35] loss: 0.162\n",
      "Got 154 / 247 with accuracy 62.35\n",
      "[74,     5] loss: 0.148\n",
      "[74,    10] loss: 0.149\n",
      "[74,    15] loss: 0.174\n",
      "[74,    20] loss: 0.168\n",
      "[74,    25] loss: 0.161\n",
      "[74,    30] loss: 0.157\n",
      "[74,    35] loss: 0.170\n",
      "Got 147 / 247 with accuracy 59.51\n",
      "[75,     5] loss: 0.172\n",
      "[75,    10] loss: 0.173\n",
      "[75,    15] loss: 0.144\n",
      "[75,    20] loss: 0.159\n",
      "[75,    25] loss: 0.141\n",
      "[75,    30] loss: 0.153\n",
      "[75,    35] loss: 0.150\n",
      "Got 158 / 247 with accuracy 63.97\n",
      "[76,     5] loss: 0.166\n",
      "[76,    10] loss: 0.118\n",
      "[76,    15] loss: 0.130\n",
      "[76,    20] loss: 0.146\n",
      "[76,    25] loss: 0.135\n",
      "[76,    30] loss: 0.162\n",
      "[76,    35] loss: 0.138\n",
      "Got 155 / 247 with accuracy 62.75\n",
      "[77,     5] loss: 0.125\n",
      "[77,    10] loss: 0.140\n",
      "[77,    15] loss: 0.131\n",
      "[77,    20] loss: 0.135\n",
      "[77,    25] loss: 0.134\n",
      "[77,    30] loss: 0.138\n",
      "[77,    35] loss: 0.149\n",
      "Got 158 / 247 with accuracy 63.97\n",
      "[78,     5] loss: 0.127\n",
      "[78,    10] loss: 0.116\n",
      "[78,    15] loss: 0.116\n",
      "[78,    20] loss: 0.134\n",
      "[78,    25] loss: 0.159\n",
      "[78,    30] loss: 0.113\n",
      "[78,    35] loss: 0.129\n",
      "Got 154 / 247 with accuracy 62.35\n",
      "[79,     5] loss: 0.110\n",
      "[79,    10] loss: 0.132\n",
      "[79,    15] loss: 0.116\n",
      "[79,    20] loss: 0.118\n",
      "[79,    25] loss: 0.115\n",
      "[79,    30] loss: 0.119\n",
      "[79,    35] loss: 0.122\n",
      "Got 153 / 247 with accuracy 61.94\n",
      "[80,     5] loss: 0.123\n",
      "[80,    10] loss: 0.116\n",
      "[80,    15] loss: 0.108\n",
      "[80,    20] loss: 0.102\n",
      "[80,    25] loss: 0.112\n",
      "[80,    30] loss: 0.121\n",
      "[80,    35] loss: 0.123\n",
      "Got 156 / 247 with accuracy 63.16\n",
      "[81,     5] loss: 0.099\n",
      "[81,    10] loss: 0.103\n",
      "[81,    15] loss: 0.111\n",
      "[81,    20] loss: 0.120\n",
      "[81,    25] loss: 0.100\n",
      "[81,    30] loss: 0.104\n",
      "[81,    35] loss: 0.095\n",
      "Got 150 / 247 with accuracy 60.73\n",
      "[82,     5] loss: 0.095\n",
      "[82,    10] loss: 0.098\n",
      "[82,    15] loss: 0.096\n",
      "[82,    20] loss: 0.109\n",
      "[82,    25] loss: 0.094\n",
      "[82,    30] loss: 0.121\n",
      "[82,    35] loss: 0.116\n",
      "Got 149 / 247 with accuracy 60.32\n",
      "[83,     5] loss: 0.100\n",
      "[83,    10] loss: 0.086\n",
      "[83,    15] loss: 0.092\n",
      "[83,    20] loss: 0.104\n",
      "[83,    25] loss: 0.094\n",
      "[83,    30] loss: 0.092\n",
      "[83,    35] loss: 0.102\n",
      "Got 150 / 247 with accuracy 60.73\n",
      "[84,     5] loss: 0.087\n",
      "[84,    10] loss: 0.089\n",
      "[84,    15] loss: 0.081\n",
      "[84,    20] loss: 0.105\n",
      "[84,    25] loss: 0.078\n",
      "[84,    30] loss: 0.099\n",
      "[84,    35] loss: 0.094\n",
      "Got 150 / 247 with accuracy 60.73\n",
      "[85,     5] loss: 0.073\n",
      "[85,    10] loss: 0.103\n",
      "[85,    15] loss: 0.072\n",
      "[85,    20] loss: 0.086\n",
      "[85,    25] loss: 0.084\n",
      "[85,    30] loss: 0.087\n",
      "[85,    35] loss: 0.083\n",
      "Got 150 / 247 with accuracy 60.73\n",
      "[86,     5] loss: 0.066\n",
      "[86,    10] loss: 0.074\n",
      "[86,    15] loss: 0.106\n",
      "[86,    20] loss: 0.082\n",
      "[86,    25] loss: 0.083\n",
      "[86,    30] loss: 0.080\n",
      "[86,    35] loss: 0.093\n",
      "Got 150 / 247 with accuracy 60.73\n",
      "[87,     5] loss: 0.070\n",
      "[87,    10] loss: 0.074\n",
      "[87,    15] loss: 0.068\n",
      "[87,    20] loss: 0.082\n",
      "[87,    25] loss: 0.077\n",
      "[87,    30] loss: 0.064\n",
      "[87,    35] loss: 0.083\n",
      "Got 152 / 247 with accuracy 61.54\n",
      "[88,     5] loss: 0.063\n",
      "[88,    10] loss: 0.074\n",
      "[88,    15] loss: 0.080\n",
      "[88,    20] loss: 0.066\n",
      "[88,    25] loss: 0.073\n",
      "[88,    30] loss: 0.061\n",
      "[88,    35] loss: 0.080\n",
      "Got 149 / 247 with accuracy 60.32\n",
      "[89,     5] loss: 0.069\n",
      "[89,    10] loss: 0.066\n",
      "[89,    15] loss: 0.078\n",
      "[89,    20] loss: 0.070\n",
      "[89,    25] loss: 0.067\n",
      "[89,    30] loss: 0.074\n",
      "[89,    35] loss: 0.062\n",
      "Got 152 / 247 with accuracy 61.54\n",
      "[90,     5] loss: 0.064\n",
      "[90,    10] loss: 0.065\n",
      "[90,    15] loss: 0.066\n",
      "[90,    20] loss: 0.067\n",
      "[90,    25] loss: 0.072\n",
      "[90,    30] loss: 0.062\n",
      "[90,    35] loss: 0.064\n",
      "Got 154 / 247 with accuracy 62.35\n",
      "[91,     5] loss: 0.063\n",
      "[91,    10] loss: 0.060\n",
      "[91,    15] loss: 0.067\n",
      "[91,    20] loss: 0.057\n",
      "[91,    25] loss: 0.059\n",
      "[91,    30] loss: 0.070\n",
      "[91,    35] loss: 0.063\n",
      "Got 156 / 247 with accuracy 63.16\n",
      "[92,     5] loss: 0.054\n",
      "[92,    10] loss: 0.059\n",
      "[92,    15] loss: 0.056\n",
      "[92,    20] loss: 0.058\n",
      "[92,    25] loss: 0.073\n",
      "[92,    30] loss: 0.064\n",
      "[92,    35] loss: 0.063\n",
      "Got 155 / 247 with accuracy 62.75\n",
      "[93,     5] loss: 0.051\n",
      "[93,    10] loss: 0.063\n",
      "[93,    15] loss: 0.059\n",
      "[93,    20] loss: 0.060\n",
      "[93,    25] loss: 0.056\n",
      "[93,    30] loss: 0.051\n",
      "[93,    35] loss: 0.050\n",
      "Got 146 / 247 with accuracy 59.11\n",
      "[94,     5] loss: 0.050\n",
      "[94,    10] loss: 0.052\n",
      "[94,    15] loss: 0.059\n",
      "[94,    20] loss: 0.049\n",
      "[94,    25] loss: 0.049\n",
      "[94,    30] loss: 0.048\n",
      "[94,    35] loss: 0.072\n",
      "Got 157 / 247 with accuracy 63.56\n",
      "[95,     5] loss: 0.051\n",
      "[95,    10] loss: 0.052\n",
      "[95,    15] loss: 0.052\n",
      "[95,    20] loss: 0.047\n",
      "[95,    25] loss: 0.063\n",
      "[95,    30] loss: 0.050\n",
      "[95,    35] loss: 0.055\n",
      "Got 145 / 247 with accuracy 58.70\n",
      "[96,     5] loss: 0.049\n",
      "[96,    10] loss: 0.052\n",
      "[96,    15] loss: 0.056\n",
      "[96,    20] loss: 0.045\n",
      "[96,    25] loss: 0.050\n",
      "[96,    30] loss: 0.047\n",
      "[96,    35] loss: 0.052\n",
      "Got 153 / 247 with accuracy 61.94\n",
      "[97,     5] loss: 0.045\n",
      "[97,    10] loss: 0.045\n",
      "[97,    15] loss: 0.042\n",
      "[97,    20] loss: 0.043\n",
      "[97,    25] loss: 0.044\n",
      "[97,    30] loss: 0.052\n",
      "[97,    35] loss: 0.052\n",
      "Got 153 / 247 with accuracy 61.94\n",
      "[98,     5] loss: 0.043\n",
      "[98,    10] loss: 0.046\n",
      "[98,    15] loss: 0.041\n",
      "[98,    20] loss: 0.042\n",
      "[98,    25] loss: 0.044\n",
      "[98,    30] loss: 0.046\n",
      "[98,    35] loss: 0.050\n",
      "Got 146 / 247 with accuracy 59.11\n",
      "[99,     5] loss: 0.045\n",
      "[99,    10] loss: 0.042\n",
      "[99,    15] loss: 0.051\n",
      "[99,    20] loss: 0.042\n",
      "[99,    25] loss: 0.042\n",
      "[99,    30] loss: 0.050\n",
      "[99,    35] loss: 0.041\n",
      "Got 149 / 247 with accuracy 60.32\n",
      "[100,     5] loss: 0.038\n",
      "[100,    10] loss: 0.046\n",
      "[100,    15] loss: 0.050\n",
      "[100,    20] loss: 0.040\n",
      "[100,    25] loss: 0.054\n",
      "[100,    30] loss: 0.042\n",
      "[100,    35] loss: 0.045\n",
      "Got 154 / 247 with accuracy 62.35\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 11677<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.05MB of 0.05MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/matt/Work/MRes-Project/laser-trees/notebooks/wandb/run-20210503_110804-2airkm60/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/matt/Work/MRes-Project/laser-trees/notebooks/wandb/run-20210503_110804-2airkm60/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Train Loss</td><td>0.1211</td></tr><tr><td>Validation Loss</td><td>1.81661</td></tr><tr><td>Train Accuracy</td><td>1.0</td></tr><tr><td>Validation Accuracy</td><td>0.62348</td></tr><tr><td>_step</td><td>99</td></tr><tr><td>_runtime</td><td>219</td></tr><tr><td>_timestamp</td><td>1620036703</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Train Loss</td><td>█▇▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Validation Loss</td><td>▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▃▅▃▄▃▄▅▅▅▅▆█▆▆▇▇▇▇▇▇</td></tr><tr><td>Train Accuracy</td><td>▁▂▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇██████████████████</td></tr><tr><td>Validation Accuracy</td><td>▁▄▆▇▇▇▇▇▇▇▇██▇▇██▇█▇█▇▇█▆▇▆▇▆▆▇▆▆▆▆▆▇▇▆▆</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">fiery-elevator-20</strong>: <a href=\"https://wandb.ai/mja2106/laser-trees/runs/2airkm60\" target=\"_blank\">https://wandb.ai/mja2106/laser-trees/runs/2airkm60</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.watch(model)\n",
    "for epoch in range(config.epochs):  # loop over the dataset multiple times\n",
    "    \n",
    "    #Training loop============================================\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        depth_images = data['depth_images']\n",
    "        labels = data['labels']\n",
    "\n",
    "        depth_images = depth_images.to(device=device)\n",
    "        labels = labels.to(device=device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(depth_images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 5 == 4:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2))\n",
    "            running_loss = 0.0\n",
    "                \n",
    "    #Test loop================================================\n",
    "    num_train_correct = 0\n",
    "    num_train_samples = 0\n",
    "    \n",
    "    num_val_correct = 0\n",
    "    num_val_samples = 0\n",
    "    \n",
    "    running_train_loss = 0\n",
    "    running_val_loss = 0\n",
    "    \n",
    "    model.eval()  \n",
    "    with torch.no_grad():\n",
    "        #Train set eval==============\n",
    "        for data in train_loader:\n",
    "            depth_images = data['depth_images']\n",
    "            labels = data['labels']\n",
    "\n",
    "            depth_images = depth_images.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "            \n",
    "            scores = model(depth_images)\n",
    "            _, predictions = scores.max(1)\n",
    "            num_train_correct += (predictions == labels).sum()\n",
    "            num_train_samples += predictions.size(0)\n",
    "            \n",
    "            running_train_loss += loss_fn(scores, labels)\n",
    "        \n",
    "        train_acc = float(num_train_correct)/float(num_train_samples)\n",
    "        train_loss = running_train_loss/len(validation_loader)\n",
    "        \n",
    "        #Test set eval===============\n",
    "        for data in validation_loader:\n",
    "            depth_images = data['depth_images']\n",
    "            labels = data['labels']\n",
    "\n",
    "            depth_images = depth_images.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "            \n",
    "            scores = model(depth_images)\n",
    "            _, predictions = scores.max(1)\n",
    "            num_val_correct += (predictions == labels).sum()\n",
    "            num_val_samples += predictions.size(0)\n",
    "            \n",
    "            running_val_loss += loss_fn(scores, labels)\n",
    "        \n",
    "        val_acc = float(num_val_correct)/float(num_val_samples)\n",
    "        val_loss = running_val_loss/len(validation_loader)\n",
    "        \n",
    "        print(f'Got {num_val_correct} / {num_val_samples} with accuracy {val_acc*100:.2f}')\n",
    "        \n",
    "        wandb.log({\n",
    "            \"Train Loss\":train_loss,\n",
    "            \"Validation Loss\":val_loss,\n",
    "            \"Train Accuracy\":train_acc,\n",
    "            \"Validation Accuracy\":val_acc\n",
    "            })\n",
    "        \n",
    "\n",
    "print('Finished Training')\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8f1187",
   "metadata": {},
   "source": [
    "### Update old object to new class (Don't run every time):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e89d813",
   "metadata": {},
   "outputs": [],
   "source": [
    "if None:\n",
    "    metadata_file = \"../data/treesXYZ/meta/META.csv\"\n",
    "    data_dir = \"../data/treesXYZ/\"\n",
    "    trees_new = utils.TreeSpeciesDataset(data_dir, metadata_file)\n",
    "\n",
    "    trees_old=torch.load('trees_old.pt')\n",
    "\n",
    "    trees_new.depth_images = trees_old.depth_images\n",
    "    trees_new.labels = trees_old.labels.long()\n",
    "\n",
    "    torch.save(trees_new, 'trees_new.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e916052",
   "metadata": {},
   "outputs": [],
   "source": [
    "if None: \n",
    "    metadata_file = \"../data/treesXYZ/meta/META.csv\"\n",
    "    data_dir = \"../data/treesXYZ/\"\n",
    "    trees_tmp = utils.TreeSpeciesDataset(data_dir=data_dir, metadata_file=metadata_file)\n",
    "    trees_tmp.depth_images=trees_data.depth_images\n",
    "    trees_tmp.labels=trees_data.labels\n",
    "    trees_tmp.image_dim=128\n",
    "    trees_tmp.camera_fov_deg=90\n",
    "    trees_tmp.f=1\n",
    "    trees_tmp.camera_dist=1.4\n",
    "\n",
    "    torch.save(trees_tmp, 'trees_128.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
